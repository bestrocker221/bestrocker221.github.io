<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Carlo Alberto Scola</title>
    <description>My Personal Blog</description>
    <link>https://carloalbertoscola.it//</link>
    <atom:link href="https://carloalbertoscola.it//feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 28 Jul 2023 19:02:54 +0200</pubDate>
    <lastBuildDate>Fri, 28 Jul 2023 19:02:54 +0200</lastBuildDate>
    <generator>Jekyll v4.3.2</generator>
    
      <item>
        <title>How to use update dynamic IP with Cloudflare API</title>
        <description>&lt;h1 id=&quot;dynamic-dns-record-update&quot;&gt;&lt;strong&gt;&lt;center&gt;Dynamic DNS record update&lt;/center&gt;&lt;/strong&gt;&lt;/h1&gt;
&lt;h2 id=&quot;cloudflare-api&quot;&gt;&lt;center&gt;Cloudflare API&lt;/center&gt;&lt;/h2&gt;
&lt;p&gt;Cloudflare DNS management is easy to use and offers simple APIs to manage all your resources. Sometimes, you might have some hosts that have a dynamic IP, or your router reboots and gets a new IP, or any other reason. What you want is a way to automatically reassign the current IP to a DNS record you own.&lt;/p&gt;

&lt;p&gt;A simple way of doing it, without installing any third party tool, is to directly send a request to Cloudflare APIs with your new IP address.&lt;/p&gt;

&lt;p&gt;How do I change a Cloudflare DNS record through APIs?&lt;/p&gt;

&lt;h2 id=&quot;how-to-automate-the-domain-ip-changes&quot;&gt;How to automate the domain IP changes&lt;/h2&gt;
&lt;p&gt;There are four simple steps:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Get your ZONE id from your main Cloudflare page: go to &lt;a href=&quot;https://dash.cloudflare.com&quot;&gt;https://dash.cloudflare.com&lt;/a&gt; and then on your domain. You will find the &lt;strong&gt;Zone ID&lt;/strong&gt; in the bottom right of the page.&lt;/li&gt;
  &lt;li&gt;Get the DNS record id of the record you want to change&lt;/li&gt;
  &lt;li&gt;GET an &lt;strong&gt;API Token&lt;/strong&gt; with permissions to modify DNS records: go to &lt;a href=&quot;https://dash.cloudflare.com/profile/api-tokens&quot;&gt;https://dash.cloudflare.com/profile/api-tokens&lt;/a&gt; and Create a new Token. Click on &lt;strong&gt;Edit zone DNS&lt;/strong&gt; template and then add your preferred zone. You can specify more options if you will. Make sure to securely store your token in a password manager as it will not be shown again.&lt;/li&gt;
  &lt;li&gt;Setup a cron job that runs a bash script and updates your DNS record&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;To get the DNS record id&lt;/strong&gt;: Once you have your ZONE ID, then you need to find out the &lt;strong&gt;Record Id&lt;/strong&gt; for the specific record you want to change. In order to do that, simply perform a call to Cloudflare APIs as follow:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl https://api.cloudflare.com/client/v4/zones/&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ZONE_ID&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;/dns_records &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Authorization: Bearer &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;CF_BEARER&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Scroll the JSON for your specific record name and copy the &lt;strong&gt;RecordId&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;update-script&quot;&gt;Update script&lt;/h2&gt;
&lt;p&gt;Here is the bash script that will do the following actions:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Get current IP (and later log it to file)&lt;/li&gt;
  &lt;li&gt;If the current IP is different from the previous IP stored in the logfile, update the DNS record on Cloudflare&lt;/li&gt;
  &lt;li&gt;Log the new IP to file with current date&lt;/li&gt;
&lt;/ol&gt;

&lt;script src=&quot;https://gist.github.com/bestrocker221/5fa7b252e5d2fa75fc46e8eb67f85cac.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;The API call shown in the script can be obviously reused at will. You can modify the &lt;em&gt;proxy&lt;/em&gt; status of the record (if you want it to be passing through Cloudflare CDN), the TTL, etc.&lt;/p&gt;

&lt;h2 id=&quot;setup-a-recurrent-cron-job&quot;&gt;Setup a recurrent cron job&lt;/h2&gt;
&lt;p&gt;To setup a recurrent cron job, simply run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;crontab -e&lt;/code&gt; and then add a line like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*/15 * * * * /PATH_OF_YOUR_FILE/update_a_record.sh&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The cron job will run every 15 minutes and will run the specified script.&lt;/p&gt;

&lt;p&gt;If you think you need to validate the IP address, you can check with a regex that is in the proper format. Here is an example that you can incorporate in the script above.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$ip_address&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;~ ^&lt;span class=&quot;o&quot;&gt;(([&lt;/span&gt;0-9]|[1-9][0-9]|1[0-9]&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;|2[0-4][0-9]|25[0-5]&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;){&lt;/span&gt;3&lt;span class=&quot;o&quot;&gt;}([&lt;/span&gt;0-9]|[1-9][0-9]|1[0-9]&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;2&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;|2[0-4][0-9]|25[0-5]&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Valid IPv4 address: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ip_address&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Invalid IPv4 address: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ip_address&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;final-considerations&quot;&gt;Final considerations&lt;/h2&gt;
&lt;p&gt;Since the script contains the API Token in cleartext, make sure to properly protect it.  &lt;strong&gt;The API Token is able to modify your DNS Zone according to what the settings were at creation time.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Remove permissions to other users to read the file or create a new user that just does that.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;I hope you found this post helpful. If you have any questions or feedback, feel free to leave a comment below.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Last modified:&lt;/em&gt; 28 July 2023&lt;/p&gt;
</description>
        <pubDate>Fri, 28 Jul 2023 00:00:00 +0200</pubDate>
        <link>https://carloalbertoscola.it//2023/linux/infrastructure/how-to-update-dynamic-ip-cloudflare/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2023/linux/infrastructure/how-to-update-dynamic-ip-cloudflare/</guid>
        
        <category>linux</category>
        
        <category>infrastructure</category>
        
        
        <category>linux</category>
        
        <category>infrastructure</category>
        
      </item>
    
      <item>
        <title>How to use custom webhooks in Authentik</title>
        <description>&lt;h1 id=&quot;ntfy-and-webhooks-in-authentik&quot;&gt;&lt;strong&gt;&lt;center&gt;Ntfy and Webhooks in Authentik&lt;/center&gt;&lt;/strong&gt;&lt;/h1&gt;
&lt;h2 id=&quot;how-to-setup-custom-webhooks-notifications&quot;&gt;&lt;center&gt;How to setup custom webhooks notifications&lt;/center&gt;&lt;/h2&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:95%;padding:30px&quot; src=&quot;/assets/authentik-dash.png&quot; /&gt;
  &lt;figcaption&gt;Goauthentik dashboard.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;what-is-authentik&quot;&gt;What is Authentik?&lt;/h2&gt;
&lt;p&gt;Authentik is an open source identity provider with great usability and flexibility. It offers a wide range of protocol support for authentication and it includes everything you need to connect to other providers.&lt;/p&gt;

&lt;p&gt;It also has support for FIDO authentication, which is great!&lt;/p&gt;

&lt;p&gt;It is possible to modify the authentication flows as you want in a super easy way. You want the MFA before the password? A click or two and it’s done.&lt;/p&gt;

&lt;p&gt;It is impressive to see such product being created and maintained by one single developer, great job!&lt;/p&gt;

&lt;p&gt;More information on their documentation official website at &lt;a href=&quot;https://goauthentik.io/docs/&quot;&gt;https://goauthentik.io/docs/&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;webhooks&quot;&gt;Webhooks&lt;/h2&gt;
&lt;p&gt;The goal of this post is to show how to properly setup webhooks. I personally have an instance of &lt;strong&gt;&lt;a href=&quot;https://ntfy.sh/&quot;&gt;ntfy&lt;/a&gt;&lt;/strong&gt; where I push my notifications and I thought it would be nice to hook up Authentik with it.&lt;/p&gt;

&lt;p&gt;How to setup ntfy in Authentik?
How to setup webhooks for ntfy in Authentik?&lt;/p&gt;

&lt;p&gt;The documentation does not show practical examples, hence why I thought it might be useful to write it down step by step.&lt;/p&gt;

&lt;p&gt;Here we are going to setup a webhook to send a message to a ntfy instance when an admin logs in.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Goal&lt;/strong&gt;: Every defined event will send a notification to ntfy, for example a login from an administrator.&lt;/p&gt;

&lt;h2 id=&quot;1--create-new-notification-transport&quot;&gt;1.  Create new notification transport&lt;/h2&gt;
&lt;p&gt;Under &lt;strong&gt;Events &amp;gt; Notification Transports&lt;/strong&gt; you can Create a new transport.&lt;/p&gt;

&lt;p&gt;Fill in the information such as name of the transport and the ntfy URL.&lt;/p&gt;

&lt;p&gt;In order to authenticate to ntfy there are two options:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Embed the auth token as a URL parameter.&lt;/li&gt;
  &lt;li&gt;Insert the token a  POST body parameter.  (untested)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first option requires the token to be set in the notification rule, the second option requires the token to be set in the property mapping.&lt;/p&gt;

&lt;p&gt;For now, I have tested the option n.1 as the HTTPS connection encrypts the conversation and nothing is leaked, but I plan to switch to the n.2 as soon as possible. I have not found out how to add custom headers in the custom request yet, hence why.&lt;/p&gt;

&lt;p&gt;Please, always be careful with ntfy token permissions, in this case the token can have the write only permissions to the specific topic and it doesn’t need to be able to read the channel.&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:95%;padding:20px&quot; src=&quot;/assets/authentik-webhook-01.png&quot; /&gt;
  &lt;figcaption&gt;Create new notification transport&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;2-create-a-notification-rule&quot;&gt;2. Create a notification rule&lt;/h2&gt;
&lt;p&gt;As per the name, the notification rules allow you to define when to trigger the notifications.&lt;/p&gt;

&lt;p&gt;In this example, we want to create a push notification when an administrator logs in.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Input the name for the rule then select the ntfy (&lt;em&gt;test-notification&lt;/em&gt; in the previous example) Transport from the list then Apply.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:95%;padding:20px&quot; src=&quot;/assets/authentik-notification-rule.png&quot; /&gt;
  &lt;figcaption&gt;Create new notification rule&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Click on the newly created Rule and you’ll see two options: &lt;strong&gt;Create &amp;amp; bind Policy&lt;/strong&gt; and &lt;strong&gt;Bind Existing Policy&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:95%;padding:20px&quot; src=&quot;/assets/authentik-pol.png&quot; /&gt;
  &lt;figcaption&gt;Empty policies for the newly created rule&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The first time you need to create it, so click the first option.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;You’ll see many types of policies, you can have fun. For now let’s use the &lt;strong&gt;Event Matcher Policy&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:95%;padding:20px&quot; src=&quot;/assets/authentik-rule2.png&quot; /&gt;
  &lt;figcaption&gt;Create new notification policy for admins login&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Set the name of the policy and then select the &lt;strong&gt;Login&lt;/strong&gt; Action. Note all the possibilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:95%;padding:20px&quot; src=&quot;/assets/authentik-rules3.png&quot; /&gt;
  &lt;figcaption&gt;Configure the Matcher Policy for admins login&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Continue and then select Group. Select the &lt;strong&gt;authentik Admins&lt;/strong&gt; here.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:95%;padding:20px&quot; src=&quot;/assets/authentik-admins-notification.png&quot; /&gt;
  &lt;figcaption&gt;Configure the Matcher Policy for admins login&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Finish the policy creation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-create-a-property-mapping&quot;&gt;3. Create a Property Mapping&lt;/h2&gt;
&lt;p&gt;Property Mappings let you define the type of payload the request will contain when notifications are triggered.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Go to &lt;strong&gt;Customizations &amp;gt; Property Mappings &amp;gt; Create&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Select &lt;strong&gt;Webhook Mapping&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:95%;padding:20px&quot; src=&quot;/assets/authentik-mapping.png&quot; /&gt;
  &lt;figcaption&gt;Configure the property mapping&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Here comes the interesting part. You can use python code here to define your request payload!&lt;/p&gt;

&lt;p&gt;In this case I wanted to print information from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;user&lt;/code&gt; object.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;gauth&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;User: {} [{}] authenticated!&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;username&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;More useful examples here:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://version-2023-5.goauthentik.io/docs/property-mappings/expression?utm_source=authentik&quot;&gt;Useful expressions examples&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://version-2023-5.goauthentik.io/docs/user-group/user&quot;&gt;User and Group objects doc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-results&quot;&gt;4. Results&lt;/h2&gt;

&lt;p&gt;This is how the notification will be rendered when the admin logs in.&lt;/p&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:95%;padding:20px&quot; src=&quot;/assets/ntfy-authentik.png&quot; /&gt;
  &lt;figcaption&gt;Ntfy notification for admin login&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;That’s all. With this example it will be easy to build more policies and notifications payloads.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;I hope you found this post helpful. If you have any questions or feedback, feel free to leave a comment below.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;Last modified:&lt;/em&gt; 05 July 2023&lt;/p&gt;
</description>
        <pubDate>Wed, 05 Jul 2023 00:00:00 +0200</pubDate>
        <link>https://carloalbertoscola.it//2023/linux/how-to-setup-webhook-authentik-notification/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2023/linux/how-to-setup-webhook-authentik-notification/</guid>
        
        <category>linux</category>
        
        <category>infrastructure</category>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>How to securely run Docker containers</title>
        <description>&lt;h1 id=&quot;securing-docker-containers&quot;&gt;&lt;strong&gt;&lt;center&gt;Securing Docker Containers&lt;/center&gt;&lt;/strong&gt;&lt;/h1&gt;
&lt;h2 id=&quot;how-to-increase-the-security-of-your-containers&quot;&gt;&lt;center&gt;How to increase the security of your containers&lt;/center&gt;&lt;/h2&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width:70%&quot; src=&quot;/assets/docker-logo.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;em&gt;Last modified:&lt;/em&gt; 05 July 2023&lt;/p&gt;

&lt;p&gt;Running Docker containers securely can be challenging and involves taking several important steps to protect both the host system and the data within the container.  &lt;strong&gt;Privilege escalation&lt;/strong&gt; has been trivial in default cases, which are seen quite commonly.&lt;/p&gt;

&lt;p&gt;The goal of this post is to give a few pointers on how to run containers in a more secure way.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Frequently &lt;strong&gt;update host OS and docker daemon&lt;/strong&gt;: make sure to always have the latest security updates.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Never expose the docker socket&lt;/strong&gt;: access to the docker UNIX socket (usually &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/var/run/docker.sock&lt;/code&gt;) gives full control over the docker daemon, which generally runs as root. This means: access to the socket == root on the host.
    &lt;ul&gt;
      &lt;li&gt;Be very careful when you see tutorials saying: “mount the docker socket with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-v /var/run/docker.sock:/var/run/docker.sock&lt;/code&gt;”&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use an &lt;strong&gt;up-to-date Docker image&lt;/strong&gt;: Make sure you use the latest Docker image available for the software you want to run. Using an outdated image can obviously lead to vulnerable applications.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Run &lt;strong&gt;root-less docker&lt;/strong&gt;: There is the option to run the docker daemon as normal user, thus drastically decreasing the privilege escalation paths. This way the containers can, at most, reach the same level of permissions as the current user, which should be hardened anyway. Root-less docker is very easy to install and configure. More on this in the next section.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use a &lt;strong&gt;non-root user&lt;/strong&gt; in the container: By default, Docker containers run as root, which can be a security risk. Instead, it is better to run the container as a non-root user. You can create a new user in the Docker image  or use the &lt;em&gt;–user&lt;/em&gt; flag when starting the container. Remember to correct the file permissions accordingly for your application, especially in  case of mounted volumes.
Moreover, on the host, often it is told to add the user to the &lt;strong&gt;docker&lt;/strong&gt; group, which is basically root. It would be recommended to run root-less docker all together to avoid any privilege escalation, &lt;a href=&quot;https://docs.docker.com/engine/security/rootless/&quot;&gt;complete guide on how to run root-less docker here&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Avoid using the “–privileged” flag&lt;/em&gt;: this allows a container to run as root, which allows for easy privilege escalation. This poses a high security risk.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Limit the &lt;strong&gt;network&lt;/strong&gt;: If no networking is needed, it can be completely disabled thus further reducing possible network movements.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Limit &lt;strong&gt;container capabilities&lt;/strong&gt;: By default, Docker containers have access to all capabilities of the host system. It is good practice to limit the capabilities of the container using the &lt;strong&gt;–cap-drop&lt;/strong&gt; flag.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use &lt;strong&gt;read-only file systems&lt;/strong&gt;: Mount the container’s file system as read-only to prevent any changes to the host system.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Limit &lt;strong&gt;resource exhaustion&lt;/strong&gt;: Use the &lt;em&gt;–memory&lt;/em&gt; and &lt;em&gt;–cpu&lt;/em&gt; flags to limit the amount of memory and CPU resources that the container can use.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use &lt;strong&gt;Docker secrets&lt;/strong&gt;: Avoid hard-coding sensitive information such as passwords and API keys in Dockerfiles or environment variables (only in swarm mode, &lt;a href=&quot;https://docs.docker.com/engine/swarm/secrets/&quot;&gt;info here&lt;/a&gt;).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Use &lt;strong&gt;&lt;a href=&quot;https://docs.docker.com/compose/&quot;&gt;Docker Compose&lt;/a&gt;&lt;/strong&gt; (my favourite): Use Docker Compose to manage multiple containers, networks, and volumes. This makes it super easy to define the entire application stack in a single file and start it with one command.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;securely-run-docker-from-command-line&quot;&gt;Securely Run Docker from Command Line&lt;/h2&gt;
&lt;p&gt;Some good command line arguments examples:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;-it&lt;/strong&gt; starts the container in interactive mode and attaches a TTY for console access.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–network=none&lt;/strong&gt; disables networking for the container.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–read-only&lt;/strong&gt; mounts the container’s file system as read-only to prevent any changes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–security-opt no-new-privileges&lt;/strong&gt; prevents the container from acquiring additional privileges.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–security-opt apparmor=docker-default&lt;/strong&gt; enables AppArmor security profiles for the container.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–cap-drop=all&lt;/strong&gt; drops all Linux capabilities from the container, limiting its abilities.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–rm&lt;/strong&gt; automatically removes the container when it exits.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–user 1001&lt;/strong&gt; runs the container as a non-root user with UID 1001.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–memory=512m&lt;/strong&gt; limits the amount of memory the container can use to 512MB.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–tmpfs  /tmp&lt;/strong&gt; mounts temporary file systems in memory to avoid writing to disk.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–mount type=tmpfs,destination=/var/tmp&lt;/strong&gt; mounts temporary file systems in memory for specific directories like /var/tmp, /var/log, and /var/lib/mysql.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;–secret id=my_secret,src=/run/secrets/my_secret&lt;/strong&gt; mounts a secret in the container’s file system to securely store and manage sensitive information.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Official documentation on the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;run&lt;/code&gt; command &lt;a href=&quot;https://docs.docker.com/engine/reference/run/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;securely-run-containers-with-docker-compose&quot;&gt;Securely run containers with Docker Compose&lt;/h2&gt;
&lt;p&gt;Example file for docker compose:&lt;/p&gt;
&lt;div class=&quot;language-yml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3&apos;&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;web&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nginx:alpine&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;443:443&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;security_opt&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;no-new-privileges:true&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;seccomp:/path/to/seccomp/profile.json&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;cap_drop&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ALL&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;read_only&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;tmpfs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/tmp&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;bind&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/path/to/nginx.conf&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/etc/nginx/nginx.conf&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;read_only&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;restart&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;always&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;One more important piece of advice is to carefully give the container the right &lt;strong&gt;file permissions&lt;/strong&gt; on the mounted volumes. Read only volumes, easily definable with for example &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-v /data:/data:ro&lt;/code&gt;, make sure the container will not be able to alter the data, restricting even further the locations where any write action is allowed at all.&lt;/p&gt;

&lt;p&gt;Giving &lt;strong&gt;read-only&lt;/strong&gt; permissions to the container also further reduce the risk of remnant data being copied over the file system or volume. Temporary data can reside in-memory only, with the use of temporary file systems (&lt;strong&gt;tmpfs&lt;/strong&gt;), which gets deleted when the container stops. The same happens for the container itself when ran with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--rm&lt;/code&gt;, by deleting the whole container after its exit.&lt;/p&gt;

&lt;p&gt;Running docker as root is simpler, requires less configuration and testing, but it exposes the host system to an uncontrolled and non-acceptable level of risk, in my opinion. Running docker as root provides more flexibility and simplicity, but it comes with a significant security risk and extra careful needs to be taken when deploying containers.&lt;/p&gt;

&lt;p&gt;Finally, &lt;strong&gt;immutable&lt;/strong&gt; containers are something I would recommend to use whenever possible.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;I hope you found this post helpful. If you have any questions or feedback, feel free to leave a comment below.&lt;/p&gt;
</description>
        <pubDate>Sat, 15 Apr 2023 00:00:00 +0200</pubDate>
        <link>https://carloalbertoscola.it//2023/linux/docker/security/how-to-securely-run-docker-containers/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2023/linux/docker/security/how-to-securely-run-docker-containers/</guid>
        
        <category>linux</category>
        
        <category>infrastructure</category>
        
        <category>docker</category>
        
        
        <category>linux</category>
        
        <category>docker</category>
        
        <category>security</category>
        
      </item>
    
      <item>
        <title>How to do create and manage Amazon IAM users with Terraform</title>
        <description>&lt;h1 id=&quot;automating-aws-iam-user-management-with-terraform&quot;&gt;&lt;strong&gt;&lt;center&gt;Automating AWS IAM User Management with Terraform&lt;/center&gt;&lt;/strong&gt;&lt;/h1&gt;
&lt;h2 id=&quot;a-guide-to-quickly-create-and-manage-iam-users-and-roles-in-aws-with-terraform&quot;&gt;&lt;center&gt;A guide to quickly create and manage IAM users and roles in AWS with Terraform&lt;/center&gt;&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Last modified:&lt;/em&gt; 16 April 2023&lt;/p&gt;

&lt;p&gt;This post is part of a series of &lt;strong&gt;&lt;a href=&quot;https://www.terraform.io/&quot;&gt;Terraform&lt;/a&gt;&lt;/strong&gt; posts related to making AWS deployment less cumbersome and more efficient. In this post, we’ll dive into the process of automating part of the IAM user management using Terraform.&lt;/p&gt;

&lt;p&gt;AWS IAM (Identity and Access Management) is a service that enables you to manage access to AWS resources securely. Creating and managing IAM users and roles through the AWS management portal can be a time-consuming process, especially when you have a large number of users to manage. Terraform can help you automate this process with the “write-once-reuse-many” principle.&lt;/p&gt;

&lt;p&gt;Infrastructure as code is becoming increasingly popular, and Terraform is a popular tool for implementing it. In this post, we’ll show you how to use Terraform to create IAM users, associate a user profile with a generated password, create access keys, and attach security policies to the user.&lt;/p&gt;

&lt;p&gt;Before we get started, here’s what you’ll need:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Terraform&lt;/li&gt;
  &lt;li&gt;Keybase (for user password encryption)&lt;/li&gt;
  &lt;li&gt;AWS account&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The post will not go into details on what is what, so let’s dive into the practical part.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Create new IAM users&lt;/li&gt;
  &lt;li&gt;Associate a user profile with a generated password&lt;/li&gt;
  &lt;li&gt;Create access keys&lt;/li&gt;
  &lt;li&gt;Attach security policies to the user&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;project-structure&quot;&gt;Project structure&lt;/h2&gt;
&lt;p&gt;The folder structure will be as follow:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;main.tf&lt;/strong&gt; (main login)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;policies.tf&lt;/strong&gt; (define the user policies)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;output.tf&lt;/strong&gt; (define the outputs)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;variables.tf&lt;/strong&gt; (store the user variables)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;getting-started-with-terraform-aws-provider&quot;&gt;Getting started with Terraform AWS Provider&lt;/h2&gt;
&lt;p&gt;To get started with Terraform AWS Provider, include the necessary module in the main.tf file as shown below:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-terraform&quot; data-lang=&quot;terraform&quot;&gt;&lt;span class=&quot;k&quot;&gt;terraform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;required_providers&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;aws&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;source&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;hashicorp/aws&quot;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;~&amp;gt; 3.0&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In the &lt;strong&gt;variables.tf&lt;/strong&gt; file, firstly define the AWS provider with its zone, then define the variables. You can define a list of users to be created as follows:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-terraform&quot; data-lang=&quot;terraform&quot;&gt;&lt;span class=&quot;k&quot;&gt;provider&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;aws&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;region&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;eu-north-1&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;username_list&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;description&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;List of equal users to create&quot;&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;type&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;mark&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;access_key_status&lt;/span&gt;     &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Active&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;john&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;access_key_status&lt;/span&gt;     &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Active&quot;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;  
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this example, we’ve defined two dictionaries containing the user’s name and the access key status that will later define whether the key should be enabled or not.&lt;/p&gt;

&lt;p&gt;Next, we’ll jump back to the &lt;strong&gt;main.tf&lt;/strong&gt; file to define the three main resources needed to create IAM users: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;aws_iam_user&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;aws_iam_access_key&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;aws_iam_user_login_profile&lt;/code&gt;. If you do not want a web console login, then skip the login profile section.&lt;/p&gt;

&lt;p&gt;These can be defined as follow, note some string variables can be defined and added in the &lt;strong&gt;variables.tf&lt;/strong&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-terraform&quot; data-lang=&quot;terraform&quot;&gt;&lt;span class=&quot;k&quot;&gt;resource&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;aws_iam_user&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;new_user&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;for_each&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;username_list&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;project_name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&quot;&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;force_destroy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;resource&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;aws_iam_access_key&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;new_user_access_key&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;for_each&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;username_list&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;pgp_key&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;keybase:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;deployer_keybase&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;# change the variables file to disallow a user&apos;s access key&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;access_key_status&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;resource&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;aws_iam_user_login_profile&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;new_user_login_profile&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;for_each&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;username_list&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;password_length&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;pgp_key&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;keybase:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;deployer_keybase&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;  
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This is all for the &lt;strong&gt;main.tf&lt;/strong&gt;. Awesome isn’t it?&lt;/p&gt;

&lt;p&gt;Now some explanation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;for_each&lt;/strong&gt; Terraform construct will create a loop and replicate the same instructions for each element contained in the value assigned. In this case, it will scroll through the &lt;em&gt;username_list&lt;/em&gt; and replicate the same resource.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;key&lt;/strong&gt; and &lt;strong&gt;value&lt;/strong&gt; are the two attribute of the &lt;em&gt;for_each&lt;/em&gt; construct.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;pgp_key&lt;/strong&gt; contains a reference to a Keybase user in the form “keybase:username”. This will instruct Terraform to fetch the public PGP key of said user and use that key to encrypt the secret generated at runtime. This way, multiple users can be created and their secrets get automatically encrypted with their PGP public key.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;status&lt;/strong&gt; in the &lt;em&gt;aws_iam_access_key&lt;/em&gt; define if the access key associated to the user is enabled or not.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-to-attach-policies-to-a-user&quot;&gt;How to attach policies to a user&lt;/h2&gt;
&lt;p&gt;In the &lt;strong&gt;policies.tf&lt;/strong&gt; we can define IAM user policies and attach them to each user.&lt;/p&gt;

&lt;p&gt;This policy example allows the user to perform S3 operations (ListBucket, GetObject, and PutObject) on the “example-bucket” S3 bucket and its objects, but denies all S3 operations on objects not located in the “logs” directory within the bucket.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-terraform&quot; data-lang=&quot;terraform&quot;&gt;&lt;span class=&quot;k&quot;&gt;resource&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;aws_iam_user_policy&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;policy_s3_example&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;for_each&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;username_list&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;s3-example&quot;&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;policy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;
{
    &quot;Version&quot;: &quot;2012-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Action&quot;: [
                &quot;s3:ListBucket&quot;,
                &quot;s3:GetObject&quot;,
                &quot;s3:PutObject&quot;
            ],
            &quot;Resource&quot;: [
                &quot;arn:aws:s3:::example-bucket&quot;,
                &quot;arn:aws:s3:::example-bucket/*&quot;
            ]
        },
        {
            &quot;Effect&quot;: &quot;Deny&quot;,
            &quot;Action&quot;: &quot;s3:*&quot;,
            &quot;NotResource&quot;: [
                &quot;arn:aws:s3:::example-bucket/logs/*&quot;
            ]
        }
    ]
}
&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;EOF
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;the-terraform-output-file&quot;&gt;The Terraform output file&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;output.tf&lt;/strong&gt; defines the Terraform outputs. These can be either through console, or i.e. to file.&lt;/p&gt;

&lt;p&gt;In this example we want to print out the generated users, and create a file for each user generated containing the credentials information.&lt;/p&gt;

&lt;p&gt;To simplify this task, a Template is created. A template file will be fed into Terraform, which in turn will populate it with the variables defined and spit out the final file.&lt;/p&gt;

&lt;p&gt;This is for example, a template file named  &lt;strong&gt;user_creds.tmpl&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-txt&quot;&gt;Username: ${username}
PGP Password: ${password}
AccessKeyID: ${access_key_id}
PGP SecretAccessKey: ${secret_access_key}
AWS Login URL: ${aws_login_url}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;${username}&lt;/code&gt; format string in the template will be populated with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;username&lt;/code&gt; variable.&lt;/p&gt;

&lt;p&gt;This is the content of &lt;strong&gt;output.tf&lt;/strong&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-terraform&quot; data-lang=&quot;terraform&quot;&gt;&lt;span class=&quot;k&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;users_created&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;new_u&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;aws_iam_user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;new_user&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;new_u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;name&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;resource&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;local_file&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;user_creds&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;for_each&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;aws_iam_user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;new_user&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;output/user_creds_&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.conf&quot;&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;templatefile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;templates/user_creds.tmpl&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;username&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;password&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;aws_iam_user_login_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;new_user_login_profile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;encrypted_password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;access_key_id&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;aws_iam_access_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;new_user_access_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;secret_access_key&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;aws_iam_access_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;new_user_access_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;secret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;aws_login_url&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;aws_login_url&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;file_permission&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;0644&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This is all!&lt;/p&gt;

&lt;h2 id=&quot;how-to-run-the-terraform-code&quot;&gt;How to run the Terraform code&lt;/h2&gt;
&lt;p&gt;We are now ready to run the Terraform code.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;First, initialize the working directory by running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;terraform init&lt;/code&gt; in the same directory as the Terraform configuration file.&lt;/li&gt;
  &lt;li&gt;Then, review the changes that Terraform will make by running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;terraform plan&lt;/code&gt;. This command will create an execution plan that shows the changes that Terraform will make to the infrastructure.&lt;/li&gt;
  &lt;li&gt;If the execution plan looks correct, we can apply the changes by running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;terraform apply&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note that some of the resources in our Terraform code will create IAM users, which may incur charges on your AWS account.&lt;/p&gt;

&lt;p&gt;If a user’s access key needs to be disabled, just change its value in the &lt;em&gt;variables.tf&lt;/em&gt; file and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;terraform apply&lt;/code&gt; to make it happen.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In this post, we have shown how to use Terraform to automate the creation and management of IAM users in AWS. By defining the user variables and their policies in the Terraform configuration files, we can quickly create and manage multiple IAM users with ease.&lt;/p&gt;

&lt;p&gt;IAM user management can be quite time-consuming when done manually through the AWS management portal. By using Terraform, we can reduce the time and effort required to manage IAM users in AWS.&lt;/p&gt;

&lt;p&gt;I hope you found this post helpful. If you have any questions or feedback, feel free to leave a comment below.&lt;/p&gt;

</description>
        <pubDate>Sat, 15 Apr 2023 00:00:00 +0200</pubDate>
        <link>https://carloalbertoscola.it//2023/linux/terraform/how-to-manage-iam-users-terraform-aws/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2023/linux/terraform/how-to-manage-iam-users-terraform-aws/</guid>
        
        <category>linux</category>
        
        <category>infrastructure</category>
        
        <category>terraform</category>
        
        
        <category>linux</category>
        
        <category>terraform</category>
        
      </item>
    
      <item>
        <title>Autopsy - A Digital Forensic Lab</title>
        <description>&lt;h1 id=&quot;autopsy-digital-forensic&quot;&gt;&lt;strong&gt;&lt;center&gt;Autopsy Digital Forensic&lt;/center&gt;&lt;/strong&gt;&lt;/h1&gt;
&lt;h2 id=&quot;quick-lab-walk-through&quot;&gt;&lt;center&gt;Quick lab walk-through&lt;/center&gt;&lt;/h2&gt;

&lt;p&gt;After following the &lt;a href=&quot;https://www.sleuthkit.org/index.php&quot;&gt;Autopsy&lt;/a&gt; (The Sleuth Kit) on-line training I decided to recap the basic functions of the Autopsy GUI digital forensic framework in a short blog post.&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/autopsy-digital-forensic.png&quot; /&gt;
&lt;figcaption&gt;Autopsy &lt;a href=&quot;https://www.sleuthkit.org/index.php&quot;&gt;here &lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;what-is-autopsy&quot;&gt;What is Autopsy&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;A program that allows you to efficiently analyze hard drives and smart phones. Contains a  C library that allows you to analyze disk images and recover files from them. It is used by law enforcement, military, and corporate examiners to investigate what happened on a computer. You can even use it to recover photos from your camera’s memory card.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Cool functions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Timeline Analysis - event viewing interface&lt;/li&gt;
  &lt;li&gt;Hash Filtering - Flag known bad files and ignore known good.&lt;/li&gt;
  &lt;li&gt;Keyword Search - Indexed keyword search to find files that mention relevant terms.&lt;/li&gt;
  &lt;li&gt;Web Artifacts - Extract history, bookmarks, and cookies from Firefox, Chrome, and IE.&lt;/li&gt;
  &lt;li&gt;Data Carving - Recover deleted files from unallocated space&lt;/li&gt;
  &lt;li&gt;Multimedia - Extract EXIF metadata from photos and videos&lt;/li&gt;
  &lt;li&gt;Indicators of Compromise - Scan a computer using STIX.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;If you want to skip the quick Autopsy introduction, jump below.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Here is the view of Autopsy windows after a successful disk import.&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/autopsy-windows.png&quot; /&gt;
&lt;figcaption&gt;Autopsy main windows after a disk import&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;central-repository-and-multi-user&quot;&gt;Central repository and multi user&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;It stores hashset to be shared with others&lt;/li&gt;
  &lt;li&gt;Access older hashsets from older cases&lt;/li&gt;
  &lt;li&gt;It uses PostgresSQL (for distributed) or SQLite (for local)&lt;/li&gt;
  &lt;li&gt;It is not enabled by default&lt;/li&gt;
  &lt;li&gt;Useful to share data to multiple users, work together on cases&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Want multi user deployment? Need central shared storage and 2 servers&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;All users need to have access to the same base dir (ex. \\crserver.local\data..)&lt;/li&gt;
  &lt;li&gt;One case can be open at a time, it will be automatically saved&lt;/li&gt;
  &lt;li&gt;autopsy.db –&amp;gt; SQLite file will store basic case info
    &lt;ul&gt;
      &lt;li&gt;module folder&lt;/li&gt;
      &lt;li&gt;report folder&lt;/li&gt;
      &lt;li&gt;export folder&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;basic-forensic-workflow&quot;&gt;&lt;strong&gt;Basic Forensic Workflow&lt;/strong&gt;&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;Create case&lt;/li&gt;
  &lt;li&gt;Add data source&lt;/li&gt;
  &lt;li&gt;Configure keywords&lt;/li&gt;
  &lt;li&gt;Run ingest with all modules&lt;/li&gt;
  &lt;li&gt;Start review as data  comes in&lt;/li&gt;
  &lt;li&gt;Update keywords as you find stuff&lt;/li&gt;
  &lt;li&gt;Tag interesting files&lt;/li&gt;
  &lt;li&gt;Generate report&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;add-new-data-source&quot;&gt;Add new data source&lt;/h2&gt;
&lt;p&gt;These type of data sources can be imported and analyzed by Autopsy.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Disk images, Virtual machine drives (vhdi, ..)&lt;/li&gt;
  &lt;li&gt;Local Drives&lt;/li&gt;
  &lt;li&gt;Local files/folders&lt;/li&gt;
  &lt;li&gt;Autopsy logical image&lt;/li&gt;
  &lt;li&gt;Unallocated raw space files&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;disk-images&quot;&gt;Disk Images&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Raw data (dd)&lt;/li&gt;
  &lt;li&gt;E01&lt;/li&gt;
  &lt;li&gt;Raw images of phones&lt;/li&gt;
  &lt;li&gt;Virtual machines files&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Remember, it will not validate E01 files on import!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Volume Systems&lt;/em&gt; organize a disk into one or more volumes (partitions):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;DOS, GPT, Mac, BSD, Solaris&lt;/li&gt;
  &lt;li&gt;will show areas of disk that are not in a volume&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;File Systems are data structures that allows to store files.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;NTFS, FAT, HFS+, ISO9660, ExtX..&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Orphan files&lt;/em&gt; are deleted files without a parent folder ($OrphanFiles)
finding them in FAT is time intensive, remember to disable it!&lt;/p&gt;

&lt;h3 id=&quot;carving&quot;&gt;Carving&lt;/h3&gt;
&lt;p&gt;Carving is the act of recovering deleted files without relying on fs knowledge but on file structure internals: ($CarvedFiles folder, done with the Ingest module)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;It scans the raw data and determine starting and ending of each file type, using the so called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;magic bytes&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;It can recover the files from unpartitioned/unformatted data&lt;/li&gt;
  &lt;li&gt;jpeg, pdf, word, zip, db, exe..&lt;/li&gt;
  &lt;li&gt;Needed when no pointers to the files exist anymore (also for deleted files!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What happens when a file is deleted?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Before deletion file1.jpg has metadata, showing size, date of creation, etc.. Every file has a pointer in the file system which allows the user to access the data on the disk related to that file.&lt;/li&gt;
  &lt;li&gt;After the deletion, the pointer is deleted so that the area of memory can’t be referenced anymore, but the data is still there in the hard drive.&lt;/li&gt;
  &lt;li&gt;To recover the data.. scan the memory, find magic bytes (beginning, end) and reconstruct the files together.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Currently not supported data sources are RAID, LVM, Bitlocker.&lt;/p&gt;

&lt;p&gt;By clicking on each file you will have many tabs showing all the information, from a hex view of the data, to the parsed output from an application or an ingestor module. Metadata and many other info are showed as well.&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/autopsy-strings.png
&quot; /&gt;
&lt;figcaption&gt;Autopsy hex viewer and strings extractor&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;You can see on the left panel, Autopsy automatically group files both per extension, MIME type, and size.&lt;/p&gt;

&lt;h1 id=&quot;autopsy-gui&quot;&gt;Autopsy GUI&lt;/h1&gt;
&lt;p&gt;Each file showed:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;can be set as &lt;strong&gt;notable&lt;/strong&gt;, &lt;strong&gt;suspicious&lt;/strong&gt;, &lt;strong&gt;note&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Test –&amp;gt; strings, EXIF&lt;/li&gt;
      &lt;li&gt;“other occurrences” tab (shows also if present in other cases)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/autopsy-noted.png&quot; /&gt;
&lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h2 id=&quot;run-ingestion-modules&quot;&gt;Run ingestion modules&lt;/h2&gt;
&lt;p&gt;When importing a data source, ingestor modules can be set up and run to obtain all kinds of information, some of the pre-packaged are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;hash calculation&lt;/li&gt;
  &lt;li&gt;hash lookup&lt;/li&gt;
  &lt;li&gt;exif extraction&lt;/li&gt;
  &lt;li&gt;add text to keyword&lt;/li&gt;
  &lt;li&gt;web browser analysis&lt;/li&gt;
  &lt;li&gt;web cookie, credentials&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/autopsy-ingest-modules
.png&quot; /&gt;
&lt;figcaption&gt;Autopsy basic ingest modules&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The ingestor has a priority -&amp;gt; user content, then unallocated space.&lt;/p&gt;

&lt;p&gt;It is possible to create &lt;strong&gt;Ingest filters&lt;/strong&gt; -&amp;gt; rules, per extension, folder, useful for TRIAGE.&lt;/p&gt;

&lt;p&gt;All the results from the Ingest modules pipelines go into “Extracted Content”.&lt;/p&gt;

&lt;h2 id=&quot;what-about-the-file-hashes&quot;&gt;What about the file hashes&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;calculate the file hash&lt;/li&gt;
  &lt;li&gt;stores it into the db for later reuse&lt;/li&gt;
  &lt;li&gt;lookup in the hashset if its known as bad, in that case it will &lt;strong&gt;tag&lt;/strong&gt; it.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Why tagging?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;to include in the report&lt;/li&gt;
  &lt;li&gt;to identify notable bad files&lt;/li&gt;
  &lt;li&gt;to update the central repo&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;start-reviewing&quot;&gt;Start reviewing&lt;/h2&gt;

&lt;p&gt;Hashsets:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;NIST National Software Reference Library (NSRL)  -&amp;gt; flags known files&lt;/li&gt;
  &lt;li&gt;custom one&lt;/li&gt;
&lt;/ul&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/autopsy-interesting.png&quot; /&gt;
&lt;figcaption&gt;Interesting file tagging for search&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Every File has a known status&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Notable, known bad&lt;/li&gt;
  &lt;li&gt;Known&lt;/li&gt;
  &lt;li&gt;Unknown&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hashset are NOT sorted, they are not indexed and searches are time consuming..&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;index it (tick the box on the ingestion module config)&lt;/li&gt;
  &lt;li&gt;then you can do binary search on it&lt;/li&gt;
  &lt;li&gt;can be stored local/remotely and reused&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When doing the indexing, do it on Linux, way more memory efficient, NOT ON WINDOWS.&lt;/p&gt;

&lt;p&gt;Here an example of the “Communication” tab showing all kinds of communications found on the disk, from emails, to phone calls and messages in case of an phone disk.&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/autipsy-mail.png&quot; /&gt;
&lt;figcaption&gt;Autopsy &quot;communication&quot; tab showing all emails found&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;create-a-new-file-type&quot;&gt;Create a new File type&lt;/h3&gt;
&lt;p&gt;You want to create a new file type, because the standard ones do not include a specific one? A new one to be highlighted for the investigation?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;custom –&amp;gt; tools/options/file types&lt;/li&gt;
  &lt;li&gt;add the new magic bytes&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;create-report&quot;&gt;Create report&lt;/h2&gt;

&lt;p&gt;Finally Autopsy can generate a HTML navigable report where all the findings, the manual tagged files and the suspicious files are listed.&lt;/p&gt;

&lt;p&gt;The timeline feature could come quite useful as well!&lt;/p&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/autopsy-timeline.png&quot; /&gt;
&lt;figcaption&gt;Autopsy timeline feature&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Note: data in the screenshot is not real, it is fake data.&lt;/p&gt;

&lt;p&gt;This was a basic walk-through of the Autopsy GUI application, and notes from the official online training.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Please feel free to make any comment! If anything is unclear, just write in the comment and I will update the post!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thanks for reading!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Carlo Alberto&lt;/em&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 10 Apr 2020 00:00:00 +0200</pubDate>
        <link>https://carloalbertoscola.it//2020/security/digital-forensic-made-easy-autopsy-sleuth/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2020/security/digital-forensic-made-easy-autopsy-sleuth/</guid>
        
        <category>security</category>
        
        <category>forensic</category>
        
        
        <category>security</category>
        
      </item>
    
      <item>
        <title>A secure, easy and encrypted cloud backup</title>
        <description>&lt;h1 id=&quot;-how-to-configure-your-remote-encrypted-backup-&quot;&gt;&lt;center style=&quot;font-weight: bold&quot;&gt; How to configure your remote encrypted backup. &lt;/center&gt;&lt;/h1&gt;
&lt;h2 id=&quot;encfs-and-rsync&quot;&gt;&lt;center style=&quot;font-weight: bold&quot;&gt;EncFS and Rsync&lt;/center&gt;&lt;/h2&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/cloud-backup-enc.jpg&quot; /&gt;
&lt;figcaption&gt;EncFS and Rsync - the &quot;almost&quot; perfect match.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;em&gt;Last modified:&lt;/em&gt; 15 April 2023&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;EncFS&lt;/strong&gt; and &lt;strong&gt;Rsync&lt;/strong&gt; together make a great combination for keeping your files safe and synced. EncFS is a FUSE-based cryptographic filesystem that encrypts files using an arbitrary directory as storage. Rsync, on the other hand, synchronizes the encrypted folder with the remote cloud so that only the already encrypted files are stored.&lt;/p&gt;

&lt;h1 id=&quot;how-encfs-works&quot;&gt;How EncFS Works&lt;/h1&gt;
&lt;p&gt;Encfs is the simplest software you can use for disk encryption on Linux. It creates two directories: one with the encrypted files to be synchronized remotely, and the other (virtual) to be mounted with a password that will show the clear text files.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/vgough/encfs&quot;&gt;&lt;strong&gt;Encfs&lt;/strong&gt;&lt;/a&gt; is a &lt;a href=&quot;https://en.wikipedia.org/wiki/EncFS&quot;&gt;&lt;em&gt;FUSE-based cryptographic filesystem&lt;/em&gt;&lt;/a&gt; which will transparently encrypt files using an arbitrary directory as storage.&lt;/p&gt;

&lt;p&gt;Encfs has been considered &lt;a href=&quot;https://wiki.archlinux.org/index.php/EncFS&quot;&gt;&lt;em&gt;the simplest software if you want to try disk encryption on Linux.&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Secondly, &lt;strong&gt;rsync&lt;/strong&gt; will keep the encrypted folder synchronized so that only the already encrypted files will be stored on the remote cloud (Dropbox, Google Drive, OneDrive, etc. or your own).&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/encfs.png&quot; /&gt;
&lt;figcaption&gt;How does it work&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Let’s start.&lt;/p&gt;

&lt;p&gt;NOTE: a probably better version in term of performance (not personally tested yet) is &lt;strong&gt;&lt;a href=&quot;https://github.com/rfjakob/gocryptfs&quot;&gt;gocryptfs&lt;/a&gt;&lt;/strong&gt;. (aspiring successor).&lt;/p&gt;

&lt;h2 id=&quot;installation&quot;&gt;&lt;strong&gt;Installation&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;You can install EncFS in three different ways: from source, using apt or using pacman. You can find the details of each method on the EncFS GitHub page.&lt;/p&gt;

&lt;h2 id=&quot;initialize-your-local-encrypted-folder&quot;&gt;&lt;strong&gt;Initialize your Local Encrypted Folder&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;To initialize your local encrypted folder, use the following command:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;encfs ~/encrypted ~/cleartext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You will be asked to choose between &lt;em&gt;default&lt;/em&gt; or &lt;em&gt;paranoia&lt;/em&gt; mode. Choose the latter if you want to set the security parameters (AES 256). The command will create an &lt;strong&gt;.encfs6.xml&lt;/strong&gt; file in the directory. This file must be kept secret and copied over to other devices you want to have clear text synchronization too.&lt;/p&gt;

&lt;h2 id=&quot;use-the-clear-text-folder&quot;&gt;&lt;strong&gt;Use the Clear Text Folder&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Now you can use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/cleartext&lt;/code&gt; folder and files will appear encrypted in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/encrypted&lt;/code&gt; folder.&lt;/p&gt;

&lt;h2 id=&quot;rsync-to-the-cloud&quot;&gt;&lt;strong&gt;Rsync TO the Cloud&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Now you can rsync the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/encrypted&lt;/code&gt; folder to your cloud of choice with &lt;strong&gt;rsync&lt;/strong&gt; :&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rsync &lt;span class=&quot;nt&quot;&gt;-arvz&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--whole-file&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--progress&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; ~/encrypted/ user@domain:/home/mycloud/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And it’s done! Now only the encrypted files will be on your remote storage.&lt;/p&gt;

&lt;p&gt;Let’s see how to have multiple setups.&lt;/p&gt;
&lt;h1 id=&quot;-encfs-on-another-machine&quot;&gt;** EncFS On Another Machine**&lt;/h1&gt;

&lt;h2 id=&quot;copy-the-encfs6xml&quot;&gt;&lt;strong&gt;Copy the .encfs6.xml&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Copy the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.encfs6.xml&lt;/code&gt; file from the previous &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/cleartext&lt;/code&gt; to this machine &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/encrypted&lt;/code&gt; folder. (recreate your two folders in this machine)&lt;/p&gt;

&lt;h2 id=&quot;initialize-your-local-encrypted-folder-1&quot;&gt;&lt;strong&gt;Initialize your local encrypted folder&lt;/strong&gt;&lt;/h2&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;encfs ~/encrypted ~/cleartext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now we are going to syncronize the local &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/encrypted&lt;/code&gt; folder with the files from the cloud.&lt;/p&gt;

&lt;h2 id=&quot;rsync-from-the-cloud&quot;&gt;&lt;strong&gt;Rsync FROM the cloud&lt;/strong&gt;&lt;/h2&gt;
&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rsync &lt;span class=&quot;nt&quot;&gt;-arvz&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--whole-file&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--progress&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; user@domain:/home/mycloud/ ~/encrypted/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;add-a-file-and-sync&quot;&gt;&lt;strong&gt;Add a file and sync&lt;/strong&gt;&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Now try to create a new file in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/cleartext/&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Push to cloud
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rsync &lt;span class=&quot;nt&quot;&gt;-arvz&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--whole-file&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--progress&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; ~/encrypted/ user@domain:/home/mycloud/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Back from the first machine
    &lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;rsync &lt;span class=&quot;nt&quot;&gt;-arvz&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--whole-file&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--progress&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-O&lt;/span&gt; user@domain:/home/mycloud/ ~/encrypted/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;shortcuts&quot;&gt;Shortcuts&lt;/h2&gt;
&lt;p&gt;Create an alias to help you, for example:&lt;/p&gt;
&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;syncNotesDown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;rsync -arvzz --whole-file --progress myvps:/home/my/mycloud/ --exclude .encfs6.xml ~/.MyNoteEncrypted &apos;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;syncNotesUp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;rsync -arvzz --whole-file --progress ~/.MyNoteEncrypted/ myvps:/home/my/mycloud/ --exclude .encfs6.xml&apos;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;mountNotes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&apos;encfs ~/.MyNoteEncrypted ~/MyNotes/&apos;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At startup when you want to mount your decrypted notes folder, just do &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mountNotes&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;All your files are synchronized between the two machines, leaving only the encrypted files over the server.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Please feel free to make any comment! If anything is unclear, just write in the comment and I will update the post!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thanks for reading!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Carlo Alberto&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 18 Jan 2020 00:00:00 +0100</pubDate>
        <link>https://carloalbertoscola.it//2020/security/linux/network/Rsync-Encfs-remote-cloud-backup-how-to/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2020/security/linux/network/Rsync-Encfs-remote-cloud-backup-how-to/</guid>
        
        <category>network</category>
        
        <category>backup</category>
        
        <category>rsync</category>
        
        <category>encfs</category>
        
        <category>cloud</category>
        
        
        <category>security</category>
        
        <category>linux</category>
        
        <category>network</category>
        
      </item>
    
      <item>
        <title>Full and Responsible disclosure, the debate.</title>
        <description>&lt;h1 id=&quot;vulnerability-disclosure---ethical-hacking&quot;&gt;&lt;strong&gt;&lt;center&gt;Vulnerability disclosure - Ethical Hacking&lt;/center&gt;&lt;/strong&gt;&lt;/h1&gt;
&lt;h2 id=&quot;responsible-vs-full-vulnerability-disclosure&quot;&gt;&lt;center&gt;Responsible vs Full vulnerability disclosure&lt;/center&gt;&lt;/h2&gt;
&lt;h3 id=&quot;the-never-ending-debate&quot;&gt;&lt;center&gt;The never ending debate&lt;/center&gt;&lt;/h3&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/windows-zero-day-twitter.png&quot; /&gt;
&lt;figcaption&gt;&quot;Microsoft Windows zero-day disclosed on Twitter, again&quot; ZDnet &lt;a href=&quot;https://www.zdnet.com/article/microsoft-windows-zero-day-disclosed-on-twitter-again/&quot;&gt;here &lt;/a&gt;&lt;/figcaption&gt;
    
&lt;/figure&gt;

&lt;p&gt;Software and hardware vulnerabilities are found every day, this means that especially we, users, are under the constant risk of losing the most important asset we have today, &lt;strong&gt;information&lt;/strong&gt;. Cyber Security vulnerabilities are weaknesses and flaws in computer systems, they can be of many different types and can be exploited in many different ways, ultimately exposing the system to external, probably malicious, threats. Vulnerabilities can aim to take down systems availability, ex-filtrate credentials, user data, secrets documents and much more.&lt;/p&gt;

&lt;p&gt;Security has been underrated by a large number of companies and SW houses for quite a while, it is mainly thanks to the more sensitization that in the recent years more focus has started to been put into applying better security policies and best practices. Although the main problem is that &lt;strong&gt;absolute security is hard if not impossible to achieve&lt;/strong&gt;, it is costly, it is broad and it is complex to implement requiring deep technical knowledge.      &lt;br /&gt;
Security is also taught to be as a “&lt;strong&gt;&lt;em&gt;process&lt;/em&gt;&lt;/strong&gt;”, in fact, following a structured way, adopting the correct mindset, from the various stages of planning and design to the multiple stages of implementation and testing is one of the best ways to decrease risks for businesses and users.&lt;/p&gt;

&lt;p&gt;The Secure Software Development Life Cycle (SDLC) is an example of such a framework that “help discover and reduce vulnerabilities early, effectively building security in it” [1]. Unfortunately, it is very easy for programmers to make errors, and those commonly turn out as vulnerabilities, found by hackers and bug hunters for example. Bulletins, CERTs, forums, mailing lists and social media are the most used means for vulnerability reporting.&lt;/p&gt;

&lt;p&gt;When it comes to vulnerabilities disclosure the topic is controversial in many ways that a clear solution is not easily pointed out. First of all, what are the types of vulnerability disclosure?&lt;/p&gt;

&lt;p&gt;Mainly, who finds a vulnerability can usually go for three options: no disclosure, &lt;em&gt;responsible disclosure&lt;/em&gt; and &lt;em&gt;full disclosure&lt;/em&gt;. The last two are the most debated since they involve different course of action for the company who needs to fix the vulnerability. Every one of the two has different pros that are backed up by competent and respected people in the field.&lt;/p&gt;

&lt;h3 id=&quot;the-responsible-disclosure&quot;&gt;The Responsible Disclosure&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Responsible disclosure&lt;/strong&gt; is essentially a way to give companies a chance to patch the security issue before the vulnerability is disclosed to the public. This involves an agreement between the two parties, in which on one side an amount of time is given to the company to fix the problem and on the other, the finder of the vulnerability agrees on not disclosing any details about it. Often it may require collaboration between the two to explain the issue and find the correct way of fixing it.&lt;/p&gt;

&lt;p&gt;Responsible disclosure is often pointed out as the preferred “ethical way to go” because it avoids putting unexpectedly out into the wild the potential tools for attacking unpatched versions of the software. This involves that companies &lt;strong&gt;do want&lt;/strong&gt; to know if there exists actual vulnerabilities in their software and are ready to take action and develop security updates.&lt;/p&gt;

&lt;p&gt;Unfortunately that is not always the case, in fact, at times the “&lt;em&gt;desire by organizations to know about their vulnerabilities is not always matched by a willingness to act on the information. This is one of the issues at the heart of the disclosure debate.&lt;/em&gt;” [2]&lt;/p&gt;

&lt;p&gt;Sometimes companies can also threaten legal actions against researchers who find out vulnerabilities in their products, that is another aspect that leads to full disclosure, in fact, not every organization employs &lt;em&gt;Bug Bounty&lt;/em&gt; programs which legally allows and stimulates researchers to find out bugs in production environments.&lt;/p&gt;

&lt;p&gt;To let more researchers find vulnerabilities, organizations should establish &lt;strong&gt;easier responsible disclosure processes and create preferential channels for faster responses&lt;/strong&gt;. That could be quite hard since all the security aspects do not bring direct benefits and income to the company, thus they tend to delay such matters.&lt;/p&gt;

&lt;p&gt;On the other hand &lt;em&gt;Travis Ormandy&lt;/em&gt;, the Google &lt;em&gt;Project Zero&lt;/em&gt; researcher uncovered in September 2019 a security bug in the famous &lt;strong&gt;Lastpass&lt;/strong&gt; password manager [3]. The bug could allow an attacker to ex-filtrate user’s previously used password from their browser. The responsible disclosure allowed Lastpass to immediately recover, fix the bug and roll the update making people safer before they even knew could be at risk.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;&lt;em&gt;BlueKeep&lt;/em&gt;&lt;/strong&gt; vulnerability reported by Microsoft on May 2019 is another case of responsible disclosure which helped the organization rolling out a security update before going public with all the details.&lt;/p&gt;

&lt;p&gt;These are a good example of how useful and safe could the responsible disclosure be, even if the major problem remains the amount of &lt;em&gt;outdated&lt;/em&gt; computers and applications still running.&lt;/p&gt;

&lt;h3 id=&quot;full-disclosure&quot;&gt;Full disclosure&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Full disclosure&lt;/strong&gt; is on the other hand when someone discovers a vulnerability and without reporting it first to the organization, he publishes it on the Internet through social networks or mailing lists. The main intent of the researcher is to &lt;strong&gt;spur companies to act immediately&lt;/strong&gt; and putting them in a potential disadvantageous situation helps to reach the goal. Furthermore, full disclosure will worsen the organization’s reputation and the only thing that can be done to get back is to fastly develop security updates.&lt;/p&gt;

&lt;p&gt;This has multiple side effects, &lt;strong&gt;the company must now address the issue as soon as possible&lt;/strong&gt; (is a good thing) but &lt;strong&gt;it is racing against attackers&lt;/strong&gt; who want to develop a working exploit to take advantage of the unpatched systems.&lt;/p&gt;

&lt;p&gt;This means the company is under bigger pressure but now is obliged to deal with it in the shortest time possible, which means there isn’t enough time to go thoroughly into the issue and a simpler workaround solution is the first thing to come up. That is a downside though, since quickest solutions are often the worse ones, and there is the risk to add other types of issues while trying to fix the previous one in the first place.&lt;/p&gt;

&lt;p&gt;In fact, &lt;em&gt;Mark Miller&lt;/em&gt;, director of &lt;em&gt;Microsoft Security Response Center&lt;/em&gt; is pro responsible disclosure and points out that “responsible disclosure, while not perfect, doesn’t increase risk as full disclosure can. Generally, responsible disclosure benefits everyone involved by providing the best possible protection for customers without forcing vendors into sacrificing quality or security or introducing additional risk.” [4]&lt;/p&gt;

&lt;p&gt;It is very common indeed that researchers alert the companies of actual vulnerabilities and that those companies do not answer at all, or even worse, as it happened to &lt;em&gt;Troy Hunt&lt;/em&gt;, the same company’s Twitter page has blocked the researcher along with his tweets about an &lt;em&gt;insecure direct object reference&lt;/em&gt; vulnerability discovery. The vulnerability allows an attacker to ex-filtrate data of each user registered on the website. [5] Troy also pointed out how difficult it has been to reach to organizations for vulnerabilities reporting. This aspect contributes to choose full disclosure.&lt;/p&gt;

&lt;p&gt;On the other hand, another big example, this time in favour of responsible disclosure, was the one in 2017 of &lt;strong&gt;&lt;em&gt;Meltdown and Spectre&lt;/em&gt;&lt;/strong&gt;, hardware vulnerabilities in central processing units (CPU) that exploit the “speculative execution”, a feature designed to improve performance of modern Intel, AMD, and ARM processors. The vulnerabilities (dated back to as far as 1995) were critical and allowed an attacker to read memory from the secure kernel space. The researchers behind it understood that the immediate future impact of this vulnerability was catastrophic with full disclosure, allowing attackers to impact almost every desktop, server, cloud, mobile device around the world. [6] Researchers used the responsible disclosure and worked with the organizations to help mitigate the issues. After the patches were rolled out, they released the PoC exploit code. This is an example of how impact less could be a responsible disclosure instead of a full disclosure since the main interest is protecting the users&lt;/p&gt;

&lt;p&gt;Although industry thought leaders like &lt;em&gt;Bruce Schneier&lt;/em&gt; argues that full disclosure provokes an immediate urgent response from organizations that otherwise, very probably, would have taken the issue very lightly. [7]&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It wasn’t until researchers published complete details of the vulnerabilities that the software companies started fixing them.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And about responsible disclosure &lt;em&gt;Schneier&lt;/em&gt; says that “&lt;strong&gt;&lt;em&gt;it remains a good idea only as long as full disclosure is the threat.&lt;/em&gt;&lt;/strong&gt;” with which I agree with.&lt;/p&gt;

&lt;p&gt;I think that responsible disclosure could be the right starting point, both ethically and consequences-wise, as soon as the company cooperates and fulfills his duty to quickly patch the vulnerabilities. In any other case, if the organization refuses to cooperate, or if the organization takes too much unmotivated time, the threat to go full disclosure is more than justified. If an individual wants to help the society and be ethical, the goal is to improve the general awareness and security of users, not to let big companies grow their profit without even trying to protect their first income source.&lt;/p&gt;

&lt;p&gt;Another aspect to consider is that undisclosed vulnerabilities or &lt;em&gt;zero days&lt;/em&gt; are worth huge amounts of money on the black markets. That is another factor that, ethic aside, could change a researcher’s mind. Prices for zero-days can easily go from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$10&apos;000&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$2&apos;500&apos;000&lt;/code&gt; and more according to &lt;strong&gt;&lt;em&gt;Zerodium&lt;/em&gt;&lt;/strong&gt; [8] which is an exploit acquisition platform.&lt;/p&gt;

&lt;p&gt;A different example was the big windows hacking tools leak from the NSA by the &lt;em&gt;Shadow Brokers&lt;/em&gt; hacking group [9], in this case, ready and working exploits for zero-day vulnerabilities went directly public. This resulted in an important race in which hackers took advantage and developed different malware and ransomware based on the ready exploits. It is the example of the infamous &lt;strong&gt;&lt;em&gt;Wannacry&lt;/em&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;em&gt;Petya&lt;/em&gt;&lt;/strong&gt; ransomware which caused several important damages to businesses and public services around the world. These ransom exploited the &lt;em&gt;EthernalBlue&lt;/em&gt; vulnerability released in 2017 [10], Microsoft quickly developed security updates, but not every device gets updated immediately and so the ransomware campaign succeeded very well.&lt;/p&gt;

&lt;p&gt;There seems to be no clear answer to the debate since the various motivations can be all seen with some level of agreement&lt;/p&gt;

&lt;p&gt;Thanks for reading&lt;/p&gt;

&lt;p&gt;/Carlo Alberto&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;[1] https://dzone.com/articles/ssdlc-101-what-is-the-secure-software-development&lt;/li&gt;
  &lt;li&gt;[2] https://www.csoonline.com/article/3259882/has-responsible-disclosure-won-the-debate.html&lt;/li&gt;
  &lt;li&gt;[3] https://www.zdnet.com/article/lastpass-bug-leaks-credentials-from-previous-site/&lt;/li&gt;
  &lt;li&gt;[4] https://www.csoonline.com/article/2121631/microsoft–responsible-vulnerability-disclosure-protects-users.html&lt;/li&gt;
  &lt;li&gt;[5] https://www.troyhunt.com/kids-pass-just-reminded-us-how-hard-responsible-disclosure-is/&lt;/li&gt;
  &lt;li&gt;[6] https://www.recordedfuture.com/meltdown-spectre-vulnerabilities/&lt;/li&gt;
  &lt;li&gt;[7] https://www.schneier.com/blog/archives/2007/01/debating_full_d.html&lt;/li&gt;
  &lt;li&gt;[8] https://zerodium.com/program.html&lt;/li&gt;
  &lt;li&gt;[9] https://www.zdnet.com/article/shadow-brokers-latest-file-drop-shows-nsa-targeted-windows-pcs-banks/&lt;/li&gt;
  &lt;li&gt;[10] https://www.zdnet.com/article/why-the-fixed-windows-eternalblue-exploit-wont-die/&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 29 Sep 2019 00:00:00 +0200</pubDate>
        <link>https://carloalbertoscola.it//2019/security/vulnerability/Full-and-Responsible-vulnerability-disclosure/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2019/security/vulnerability/Full-and-Responsible-vulnerability-disclosure/</guid>
        
        
        <category>security</category>
        
        <category>vulnerability</category>
        
      </item>
    
      <item>
        <title>What is Subdomain Takeover and how to defend.</title>
        <description>&lt;h1 id=&quot;-subdomain-takeover-and-how-to-avoid-it-&quot;&gt;&lt;strong&gt;&lt;center&gt; SubDomain Takeover and how to avoid it. &lt;/center&gt;&lt;/strong&gt;&lt;/h1&gt;
&lt;h2 id=&quot;how-to-spot-unused-subdomains&quot;&gt;&lt;strong&gt;&lt;center&gt;How to spot unused subdomains&lt;/center&gt;&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Note, this is a very high level introduction and overview of what a subdomain takeover is, with some examples happened against known websites.&lt;/p&gt;

&lt;h3 id=&quot;what-is-dns-zone-delegation&quot;&gt;What is DNS Zone Delegation&lt;/h3&gt;

&lt;p&gt;DNS is a  hierarchy structure made of a series of delegations: from the root (&lt;strong&gt;.&lt;/strong&gt;) zone, to (&lt;strong&gt;.com&lt;/strong&gt;) zone (alias &lt;strong&gt;Top Level Domain&lt;/strong&gt; or &lt;strong&gt;TLD&lt;/strong&gt;), to (&lt;strong&gt;example.com&lt;/strong&gt;) zone. How are all the zones linked? Delegation.&lt;/p&gt;

&lt;p&gt;In fact the &lt;strong&gt;.com&lt;/strong&gt; &lt;em&gt;delegate&lt;/em&gt; the authority of &lt;strong&gt;example.com&lt;/strong&gt; to its own &lt;em&gt;zone&lt;/em&gt;.&lt;/p&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto;&quot; src=&quot;/assets/zone-delegation-dns.gif&quot; /&gt;
&lt;figcaption&gt;Figure 1. from &lt;a href=&quot;https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/cc771640(v=ws.11)&quot;&gt;here &lt;/a&gt;&lt;/figcaption&gt;
    
&lt;/figure&gt;

&lt;p&gt;DNS provide options to divide name-spaces into one or more zones, which can be stored or replicated to others DNS servers. If you want to create additional zones keep in mind:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Do you want to delegate part of DNS management to another location?&lt;/li&gt;
  &lt;li&gt;Do you want to distribute traffic, load balance, have redundancy and ultimately to improve resolutions?&lt;/li&gt;
  &lt;li&gt;Do you want to extend name-spaces by adding multiple subdomains at once?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Remember that for each new zone that you create, you need delegation records in other zones that point to the authoritative DNS servers for the new zone.&lt;/p&gt;

&lt;p&gt;When a standard primary zone is first created, all the resource record information is stored as a text file on a single DNS server. This server acts as the primary master for the zone. Zone information can be replicated to other DNS servers to improve fault tolerance and server performance.&lt;/p&gt;

&lt;h2 id=&quot;subdomain-to-a-new-zone&quot;&gt;Subdomain to a new zone&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://bestrockers.ddns.net/res/zone-deleg.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;&lt;em&gt;Figure 1.&lt;/em&gt;&lt;/strong&gt; shows a DNS hierarchy for a new &lt;strong&gt;&lt;em&gt;example.microsoft.com&lt;/em&gt;&lt;/strong&gt; domain zone (&lt;strong&gt;ns.1.us.example.microsoft.com&lt;/strong&gt;).&lt;/p&gt;

&lt;p&gt;To make authoritative DNS servers know about the new delegated zone, two DNS resource record are required:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A name-server NS RR to advertise that &lt;strong&gt;&lt;a href=&quot;http://ns.1.us.example.microsoft.com&quot;&gt;ns.1.us.example.microsoft.com&lt;/a&gt;&lt;/strong&gt; is an authoritative DNS server for the delegated domain.&lt;/li&gt;
  &lt;li&gt;A host (A or AAAA) RR to necessarily resolve the name to its IP address.
Ref: https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/cc771640(v=ws.11)&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;the-subdomain-takeover&quot;&gt;&lt;strong&gt;The Subdomain Takeover&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;It is considered a high severity threat and boils down to the registration of a domain by somebody else (with bad intentions) in order to gain control over one or more (sub)domains. This attack vector could lead to authentication bypass for example:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://hackerone.com/reports/172137&quot;&gt;Authentication bypass on sso.ubnt.com via subdomain takeover of ping.ubnt.com&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is not a standard vulnerability, but a chain of two more exotic vulnerabilities leading to a full authentication bypass of your SSO login system at &lt;strong&gt;sso.ubnt.com&lt;/strong&gt; (via account.ubnt.com). The root cause of this authentication bypass is two-fold:&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;Subdomain &lt;strong&gt;ping.ubnt.com&lt;/strong&gt; was pointing to Amazon Cloudfront CDN, but the hostname was not registered there anymore. This allowed me to fully takeover this domain. It is now serving content of my own webserver, both over http and https.&lt;/li&gt;
    &lt;li&gt;The session cookie of your SSO subdomain &lt;strong&gt;sso.ubnt.com&lt;/strong&gt; is (deliberately?) shared with all &lt;strong&gt;https://*.ubnt.com&lt;/strong&gt; subdomains through its “domain=.ubnt.com” attribute. This allows leakage of this high-value session cookie to the overtaken subdomain &lt;strong&gt;https://ping.ubnt.com&lt;/strong&gt; in all modern browsers.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;scenario&quot;&gt;Scenario&lt;/h2&gt;

&lt;p&gt;Let’s say a business (e-commerce) is using &lt;strong&gt;&lt;a href=&quot;http://example.com&quot;&gt;example.com&lt;/a&gt;&lt;/strong&gt; as primary domain. E-commerce providers (e.g. Shopify, BigCommerce, Magento, Yokart, Big Kartel) will give you a domain for your store like &lt;strong&gt;&lt;em&gt;&lt;a href=&quot;http://shopexample.ecommerceplatform.com&quot;&gt;shopexample.ecommerceplatform.com&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt; but you want to use your own domain for example &lt;strong&gt;shop.example.com.&lt;/strong&gt; You have two options.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A &lt;strong&gt;301/302 HTTP redirect&lt;/strong&gt; from &lt;a href=&quot;http://shop.example.com&quot;&gt;shop.example.com&lt;/a&gt; to the domain of the ecommerce platform but will replace the URL in the browser URL bar.&lt;/li&gt;
  &lt;li&gt;A &lt;strong&gt;CNAME DNS record&lt;/strong&gt; that delegate DNS resolution directly to the e-commerce provider. Here the URL in the bar remain unchanged.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;if one year later you dismiss the subscription, it can happen to &lt;strong&gt;forget to update or simply remove the CNAME record in your DNS zone file.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;remove-the-cname-record-to-avoid-subdomain-takeover&quot;&gt;&lt;strong&gt;Remove the CNAME record to avoid Subdomain Takeover&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;When you don’t remove the CNAME record from your DNS zone file, &lt;strong&gt;anybody&lt;/strong&gt; can register a new store in the same e-commerce platform suppliers environment &lt;strong&gt;and therefore aim to takeover &lt;a href=&quot;http://shop.example.com/&quot;&gt;shop.example.com&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Rule N.1:  Check DNS configurations for subdomains pointing at services not in use.&lt;/p&gt;

&lt;h2 id=&quot;cloud-providers-and-cdns&quot;&gt;Cloud providers and CDNs&lt;/h2&gt;

&lt;p&gt;Example. Amazon CloudFront (CDN service) works with the concept of “distributions” (set of static files hosted on the Amazon Cloudfront Edge servers.). After creating a new distribution a new domain name is randomly generated like &lt;em&gt;&lt;a href=&quot;http://r42opslbajrw244.cloudfront.net&quot;&gt;r42opslbajrw244.cloudfront.net&lt;/a&gt; but:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;No 1:1 mapping, no dedicated IP address for every distribution but m:n mapping (virtual hosting in Edge servers). HTTP Host Header tells the server which hostname to serve.&lt;/p&gt;

&lt;p&gt;If you want to use &lt;a href=&quot;http://shop.example.com&quot;&gt;shop.example.com&lt;/a&gt; then a CNAME record like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;shop.example.com.	600	IN	CNAME	r42opslbajrw244.cloudfront.net.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;with an Alternate Domain Name set on Cloudfront for shop.example.com&lt;/p&gt;

&lt;h1 id=&quot;what-does-this-mean&quot;&gt;WHAT DOES THIS MEAN?&lt;/h1&gt;

&lt;p&gt;If an attacker can spot a subdomain unused with improper (but still valid) DNS configuration, he can register a new domain with the same name and being pointed to the “takeovered” one. He can trick users to visit the domain as they will not know if they are surfing an illegitimate website, an an attacker can easily steal an &lt;strong&gt;authentication cookie&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;usagov-vulnerable-to-subdomain-takeover&quot;&gt;&lt;a href=&quot;http://usa.gov/&quot;&gt;USA.gov&lt;/a&gt; vulnerable to Subdomain Takeover&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;suspicious subdomain &lt;a href=&quot;http://api.usa.gov/&quot;&gt;api.usa.gov&lt;/a&gt; with 404 HTTP code&lt;/li&gt;
  &lt;li&gt;the &lt;a href=&quot;http://api.usa.gov/&quot;&gt;api.usa.gov&lt;/a&gt; points to CNAME record &lt;a href=&quot;http://api-usa-gov.domains.api.data.gov/&quot;&gt;api-usa-gov.domains.api.data.gov&lt;/a&gt; which in turn has A records pointing to AWS servers.&lt;/li&gt;
  &lt;li&gt;subdomain not registered in GitHub pages anymore.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ref: &lt;a href=&quot;https://blog.sweepatic.com/usa-secured-by-sweepatic/&quot;&gt;https://blog.sweepatic.com/usa-secured-by-sweepatic/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;subdomain-enumeration&quot;&gt;&lt;strong&gt;Subdomain Enumeration&lt;/strong&gt;&lt;/h2&gt;

&lt;h3 id=&quot;how-can-we-spot-subdomains&quot;&gt;How can we spot subdomains?&lt;/h3&gt;

&lt;p&gt;Subdomain enumeration is an important part of the reconnaissance phase in the &lt;strong&gt;cyber kill chain.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Subdomain enumeration is the process of finding valid (resolvable) subdomains for one or more domain(s). Unless the DNS server exposes a full DNS zone (via &lt;a href=&quot;https://cr.yp.to/djbdns/axfr-notes.html&quot;&gt;AFXR&lt;/a&gt; or a “mechanism for replicating DNS data across DNS servers”), it is really hard to obtain a list of existing subdomains.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;dictionary of common names (no strange names)&lt;/li&gt;
  &lt;li&gt;crawl second level domain to find links to subdomains (google dorks is faster)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Facebook Certificate Transparency&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developers.facebook.com/tools/ct&quot;&gt;https://developers.facebook.com/tools/ct&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;let you subscribe to every change in a domain /subdomain certificate&lt;/p&gt;

&lt;h3 id=&quot;tools&quot;&gt;&lt;strong&gt;Tools&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 id=&quot;dns-zone-transfer-very-uncommon-nowadays&quot;&gt;DNS Zone Transfer (very uncommon nowadays)&lt;/h4&gt;

&lt;p&gt;AXFR request directly on the DNS server:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dig @ns.example.com example=.com AXFR
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The best practice advises administrators to allow AXFR requests only from authorized DNS servers, so the above technique will probably not work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NSEC walking attack&lt;/strong&gt;, which enumerates DNSSEC-signed zones. (&lt;a href=&quot;https://nmap.org/nsedoc/scripts/dns-nsec-enum.html&quot;&gt;https://nmap.org/nsedoc/scripts/dns-nsec-enum.html&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&quot;google-dorks&quot;&gt;Google Dorks&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;site:example.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;rapid7-dns-dataset&quot;&gt;Rapid7 DNS dataset&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://opendata.rapid7.com/sonar.fdns_v2/&quot;&gt;https://opendata.rapid7.com/sonar.fdns_v2/&lt;/a&gt; provide a large dataset of domains found on the internet.&lt;/p&gt;

&lt;p&gt;To skim and search for:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;zcat snapshop.json.gz | 
jq -r &apos;if (.name | test(&quot;\\.example\\.com$&quot;)) then .name else empty end&apos;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;jq&lt;/strong&gt; (&lt;a href=&quot;https://stedolan.github.io/jq/&quot;&gt;https://stedolan.github.io/jq/&lt;/a&gt;) is like &lt;strong&gt;sed&lt;/strong&gt; for large json data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Or just use —&amp;gt; &lt;a href=&quot;https://dnsdumpster.com/&quot;&gt;https://dnsdumpster.com/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;subject-alternative-name&quot;&gt;Subject Alternative Name&lt;/h2&gt;
&lt;p&gt;Some tools for finding subdomains:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://censys.io/&quot;&gt;Censys.io&lt;/a&gt; —&amp;gt;  &lt;a href=&quot;https://censys.io/certificates?q=.example.com&quot;&gt;https://censys.io/certificates?q=.example.com&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://crt.sh/&quot;&gt;Crt.sh&lt;/a&gt; —&amp;gt; &lt;a href=&quot;https://crt.sh/?q=%25.example.com&quot;&gt;https://crt.sh/?q=%.example.com&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/aboul3la/Sublist3r&quot;&gt;Sublist3r&lt;/a&gt; —&amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python [sublist3r.py](http://sublist3r.py/) -d [example.com](http://example.com/)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Refs at &lt;a href=&quot;https://blog.sweepatic.com/art-of-subdomain-enumeration/&quot;&gt;https://blog.sweepatic.com/art-of-subdomain-enumeration/&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;More coming soon! Stay cool! and safe ;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Please feel free to make any comment! If anything is unclear, just write in the comment and I will update the post!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thanks for reading!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Carlo Alberto&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 05 Sep 2019 00:00:00 +0200</pubDate>
        <link>https://carloalbertoscola.it//2019/web/security/SubDomain-Takeover/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2019/web/security/SubDomain-Takeover/</guid>
        
        
        <category>web</category>
        
        <category>security</category>
        
      </item>
    
      <item>
        <title>Network Function Virtualization, Middleboxes and Cloud Load Balancing</title>
        <description>&lt;h1 class=&quot;no_toc&quot; id=&quot;nfv-cloud-and-middleboxes&quot;&gt;&lt;strong&gt;&lt;center&gt;NFV, Cloud and Middleboxes&lt;/center&gt;&lt;/strong&gt;&lt;/h1&gt;
&lt;h2 class=&quot;no_toc&quot; id=&quot;in-data-plane-recovery&quot;&gt;&lt;strong&gt;&lt;center&gt;In-data-plane recovery&lt;/center&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 class=&quot;no_toc&quot; id=&quot;-research-papers-review-and-summary-&quot;&gt;&lt;center&gt; Research papers review and summary &lt;/center&gt;&lt;/h3&gt;
&lt;h3 class=&quot;no_toc&quot; id=&quot;-part-2--here-link-to-part-1--&quot;&gt;&lt;center&gt; PART 2.  &lt;a href=&quot;/2019/network/sdn/software-defined-networking-introduction/&quot;&gt;Here Link to part 1.&lt;/a&gt;  &lt;/center&gt;&lt;/h3&gt;
&lt;p&gt;In &lt;strong&gt;&lt;a href=&quot;/2019/network/sdn/python/software-defined-networking-nfv-example-with-pox-click-openflow/&quot;&gt;this post&lt;/a&gt;&lt;/strong&gt; there is a practical step-by-step project with POX SDN, OpenFlow, Click and NFV.&lt;/p&gt;

&lt;h3 class=&quot;no_toc&quot; id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h3&gt;
&lt;div id=&quot;inline_toc&quot;&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#what-about-middleboxes&quot; id=&quot;markdown-toc-what-about-middleboxes&quot;&gt;&lt;strong&gt;What about MIDDLEBOXES?&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions&quot; id=&quot;markdown-toc-contributions&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#outsourcing-middleboxes-to-the-cloud-any-benefits&quot; id=&quot;markdown-toc-outsourcing-middleboxes-to-the-cloud-any-benefits&quot;&gt;&lt;strong&gt;Outsourcing Middleboxes to the cloud, any benefits?&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions-1&quot; id=&quot;markdown-toc-contributions-1&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#a-network-function-virtualization-platform&quot; id=&quot;markdown-toc-a-network-function-virtualization-platform&quot;&gt;&lt;strong&gt;A Network Function Virtualization Platform&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions-2&quot; id=&quot;markdown-toc-contributions-2&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#cloud-load-balancing&quot; id=&quot;markdown-toc-cloud-load-balancing&quot;&gt;&lt;strong&gt;Cloud load balancing&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions-3&quot; id=&quot;markdown-toc-contributions-3&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#connectivity-recovery-directly-in-the-data-plane&quot; id=&quot;markdown-toc-connectivity-recovery-directly-in-the-data-plane&quot;&gt;&lt;strong&gt;Connectivity recovery directly in the Data-Plane&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions-4&quot; id=&quot;markdown-toc-contributions-4&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#here-link-to-part-1&quot; id=&quot;markdown-toc-here-link-to-part-1&quot;&gt;&lt;strong&gt;Here link to PART 1&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references&quot; id=&quot;markdown-toc-references&quot;&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;hr /&gt;

&lt;div&gt;
&lt;span class=&quot;read-time-txt&quot;&gt;Reading time:&lt;/span&gt;
&lt;span class=&quot;read-time-val&quot;&gt;


  9 mins

&lt;/span&gt;
	 
&lt;p class=&quot;read-time-date&quot;&gt;
	&lt;script&gt;
	var today = new Date();
	weekday = [&quot;Sunday&quot;, &quot;Monday&quot;,&quot;Tuesday&quot;, &quot;Wednesday&quot;,&quot;Thursday&quot;, &quot;Friday&quot;,&quot;Saturday&quot;];
	mlist = [ &quot;January&quot;, &quot;February&quot;, &quot;March&quot;, &quot;April&quot;, &quot;May&quot;, &quot;June&quot;, &quot;July&quot;, &quot;August&quot;, &quot;September&quot;, &quot;October&quot;, &quot;November&quot;, &quot;December&quot; ];
	var time = today.getHours() + &quot;:&quot; + today.getMinutes();
	var d = weekday[today.getDay()] + &quot; &quot; +today.getDate() + &quot; &quot; + mlist[today.getMonth()] + &quot; &quot; + today.getFullYear();
	document.write(d + &quot;  &quot; + time);
	&lt;/script&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;what-about-middleboxes&quot;&gt;&lt;strong&gt;What about MIDDLEBOXES?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Networks need middleboxes like IDS, Firewalls, Concentrator, Proxy for further packet processing, fact is that interconnecting and manually configuring the routing policies is &lt;strong&gt;hard and error prone&lt;/strong&gt;. An SDN approach could greatly improve the flexibility but does not offer the required L2/L3 methods out-of-the-box.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SIMPLE&lt;/strong&gt;’s &lt;a class=&quot;citation&quot; href=&quot;#simple&quot;&gt;[1]&lt;/a&gt; aim is to &lt;strong&gt;simplify the policy enforcement&lt;/strong&gt; for an efficient &lt;strong&gt;traffic steering&lt;/strong&gt; in the network. It faces some challenges like &lt;em&gt;composition&lt;/em&gt;, &lt;em&gt;load balancing&lt;/em&gt; and &lt;em&gt;packet modifications&lt;/em&gt;. Packets in the network need to follow specific middleboxes paths, they can flow in different direction and can &lt;strong&gt;raise ambiguous forwarding decisions&lt;/strong&gt;, also Middleboxes can modify part of packets, making it harder for the SDN to determine the right paths.&lt;/p&gt;

&lt;p&gt;This is what SIMPLE addresses with the use of a &lt;strong&gt;unified resource management&lt;/strong&gt; together with a dynamic packet handler which automatically adapts rules to middleboxes packets modifications.&lt;/p&gt;

&lt;p&gt;SIMPLE is composed of &lt;em&gt;ResMgr&lt;/em&gt; which takes the network as input and outputs a set of of rules, the &lt;em&gt;DynHandler&lt;/em&gt; which keeps mappings between packets and a &lt;em&gt;RuleGen&lt;/em&gt; which actually generate the configurations. It is important to note that all the operations are resource limited by the amount of CPU, memory and especially switches TCAM flow table size. In fact the optimization decomposition is part of the challenges SIMPLE try to address with an &lt;strong&gt;offline pruning stage followed by a more frequent online LP calculation&lt;/strong&gt; when traffic pattern changes. SIMPLE showed to have very low controller overhead but can gain over 6 times more performances on load balancing compared with today implementations.&lt;/p&gt;

&lt;h4 id=&quot;contributions&quot;&gt;Contributions&lt;/h4&gt;
&lt;p&gt;The aim of the paper is to propose &lt;strong&gt;a way to relieve network operators from thinking where to apply policies and instead focusing on what&lt;/strong&gt;. In fact SIMPLE &lt;strong&gt;does not change anything in the middleboxes&lt;/strong&gt;, it is only allowed to configure the SDN switches.&lt;/p&gt;

&lt;p&gt;The basic policy element here is the &lt;em&gt;PolicyChain&lt;/em&gt; which is the set of requirements for a specific traffic class that must undergo a specific middleboxes path. Great work is done by the &lt;em&gt;DynHandler&lt;/em&gt; to map incoming/outgoing packets using &lt;em&gt;payload similarity&lt;/em&gt; and &lt;em&gt;flow correlation&lt;/em&gt; techniques (achieving 95% of marching accuracy). This can happen because first few packets of each new flow are sent to the DynHandler for evaluation.&lt;/p&gt;

&lt;p&gt;The ambiguous forwarding is greatly solved with the use of &lt;strong&gt;&lt;em&gt;SwitchTunnel&lt;/em&gt;&lt;/strong&gt; together with a &lt;em&gt;ProcState&lt;/em&gt; and &lt;em&gt;Tag&lt;/em&gt; element. Even though these approach are not new, here they are firstly applied to middleboxes. These allow switches to understand in which “state” a packet is and deal with the right forwarding decision (ex: when a packet has to go backwards two or more times to the same switch).&lt;/p&gt;

&lt;p&gt;Failures and Policy changes are dealt with the pre-computation of a set of configurations (like a &lt;strong&gt;fast-reroute&lt;/strong&gt;).&lt;/p&gt;

&lt;h2 id=&quot;outsourcing-middleboxes-to-the-cloud-any-benefits&quot;&gt;&lt;strong&gt;Outsourcing Middleboxes to the cloud, any benefits?&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;In large networks today the &lt;strong&gt;number of middleboxes deployed is very high&lt;/strong&gt;, expensive to manage and brings difficult manual policy management. Middleboxes are used for security reasons like IDS, Firewalls, performance improving like Proxies and caching and finally for reducing bandwidth usage costs with WAN optimizers. Hardware has to be replaced on average every five years and costs can rise very high depending on the network scale, &lt;strong&gt;for example for a network of 2850 routers, around 1940 middleboxes have been counted&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The paper shows &lt;strong&gt;APLOMB&lt;/strong&gt; &lt;a class=&quot;citation&quot; href=&quot;#midd-outsourc&quot;&gt;[2]&lt;/a&gt;, a way of outsourcing such middlebox burden to the cloud along with advantages and disadvantages.
Middleboxes are often required some properties like &lt;strong&gt;being on-path&lt;/strong&gt;, choke points and local to an enterprise, but with outsourcing these requirements can be shifted.&lt;/p&gt;

&lt;figure&gt;
    &lt;img style=&quot;display: block; margin: auto; width: 60%; padding-top:25px&quot; src=&quot;/assets/aplomb1.png&quot; /&gt;
&lt;figcaption&gt;Figure 8. Fraction of network administrators who estimated misconfiguration, overload, or physical/electrical failure as the most common cause of middlebox failure. Figure from &lt;a href=&quot;https://www.semanticscholar.org/paper/Making-middleboxes-someone-else&apos;s-problem%3A-network-Sherry-Hasan/742c42f5cd7c1f195fa83c8c1611ee7e62c9c81f/figure/1&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
    
&lt;/figure&gt;
&lt;p&gt;APLOMB aims to have the &lt;strong&gt;same functional equivalence as traditional deployments&lt;/strong&gt;, adding no complexity at the enterprise while, most importantly, &lt;strong&gt;maintaining an acceptable performance/latency overhead.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Paper shows latency differences between three approaches for relying traffic to Cloud Providers, but the DNS is chosen over the IP redirection because allows flows to be routed towards and from the same CP (Cloud Provider) POP.&lt;/p&gt;

&lt;p&gt;Substantially the CP provides the enterprise DNS resolution service and traffic from the Internet immediately reach the CP, and is then tunneled towards the enterprise. One or multiple (for scaling and load balancing) APLOMB gateways are deployed at the enterprise which are the endpoints connecting to the CP.&lt;/p&gt;

&lt;figure&gt;
    &lt;img style=&quot;display: block; margin: auto; width: 70%; padding-top:25px&quot; src=&quot;/assets/aplomb-dns.png&quot; /&gt;
&lt;figcaption&gt;Figure 9. DNS-based redirection minimizes latency and allows providers to control PoP selection for each request. Figure from &lt;a href=&quot;https://www.semanticscholar.org/paper/Making-middleboxes-someone-else&apos;s-problem%3A-network-Sherry-Hasan/742c42f5cd7c1f195fa83c8c1611ee7e62c9c81f/figure/7&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
    
&lt;/figure&gt;

&lt;p&gt;Evaluations have shown that on average 60% of the middleboxes can be outsourced with less than 5ms latency and low bandwidth increase.&lt;/p&gt;

&lt;h4 id=&quot;contributions-1&quot;&gt;Contributions&lt;/h4&gt;
&lt;p&gt;The paper points out an analysis whether outsourcing the deployment of middleboxes from large networks is feasible, convenient and simple. In fact it provides a study of pros and cons applied to &lt;strong&gt;57 real world deployments&lt;/strong&gt; along with a complete implementation and evaluation.&lt;/p&gt;

&lt;p&gt;The use of CP for middleboxes outsourcing &lt;strong&gt;may bring benefits to all sized businesses&lt;/strong&gt;, because the cost for maintaining and over-provisioning such infrastructure is quite high, especially for small and home offices.&lt;/p&gt;

&lt;p&gt;Paper shows &lt;strong&gt;different designs of traffic redirection&lt;/strong&gt; available and evaluate logical correctness and latency of each one, in fact APLOMB chose to use DNS redirection along with &lt;strong&gt;compression support in the APLOMB+ gateway&lt;/strong&gt; for better bandwidth usage.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Smart Redirection&lt;/em&gt; is a great feature introduced were to reduce latency, the path is not chosen to be the best from POP to the enterprise, instead it is &lt;em&gt;destination dependent&lt;/em&gt; and computed as e2e best latency path from user to POP to the enterprise.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;Cloud controller&lt;/em&gt; acts as control plane and has a central role of optimizing redirection strategies, pushing policies to Middleboxes and dynamically scaling capacity in order to meet usage demands.&lt;/p&gt;

&lt;h2 id=&quot;a-network-function-virtualization-platform&quot;&gt;&lt;strong&gt;A Network Function Virtualization Platform&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;The paper &lt;a class=&quot;citation&quot; href=&quot;#metron&quot;&gt;[3]&lt;/a&gt; presents &lt;strong&gt;&lt;em&gt;Metron&lt;/em&gt;&lt;/strong&gt;, a &lt;em&gt;Network Function Virtualization&lt;/em&gt; platform that allows to achieve very &lt;strong&gt;high resource utilization&lt;/strong&gt; in commodity server hardware and &lt;strong&gt;very high throughput&lt;/strong&gt; while inspecting traffic.&lt;/p&gt;

&lt;p&gt;It achieves so by &lt;strong&gt;offloading&lt;/strong&gt; part of the &lt;strong&gt;computation to the network device&lt;/strong&gt;, using &lt;strong&gt;smart tagging&lt;/strong&gt; for classifying traffic classes and utilizing those tags for quick &lt;strong&gt;hardware dispatching&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Indeed one of the biggest problem is when a packet arrives, &lt;em&gt;how to locate the core responsible for processing it&lt;/em&gt;. This would cause &lt;strong&gt;costly inter-core communication&lt;/strong&gt; in the case the wrong core is chosen so packet has to be transferred from a core’s L2/L3 cache to another core’s L2/L3 cache and that is what Metron solves.&lt;/p&gt;

&lt;p&gt;Metron allows packet to always stay in the same cache, raising the maximum speed to the cache’s highest one. Packet classification also greatly simplify the load balancing, introducing a quick way to split traffic among different classes or cores, in fact if there is overload the controller (&lt;em&gt;ONOS&lt;/em&gt;) can re-balance the traffic classes.&lt;/p&gt;

&lt;figure&gt;
    &lt;img style=&quot;display: block; margin: auto; width: 70%; padding-top:25px&quot; src=&quot;/assets/metron.png&quot; /&gt;
&lt;figcaption&gt;Figure 10. Metron NFV Service Chain. From Source, to Tagging to Hardware Dispatching. Figure from &lt;a href=&quot;https://www.kth.se/blogs/tcc/2018/04/metron-presentation-with-video-at-nsdi-2018-nfv-service-chains-at-the-true-speed-of-the-underlying-hardware/&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
    
&lt;/figure&gt;

&lt;p&gt;Data Plane follows a master/slave architecture where the master is an agent that interact with HW and the controller, then there is the TAG module with dynamically associates tags to traffic classes to control load distribution and advertise to the controller. As in the Control Plane instead, Metron combines all the pkt processing graphs into a &lt;em&gt;Service Chain&lt;/em&gt; with NFs.&lt;/p&gt;

&lt;p&gt;In case of failures Metron has always a &lt;strong&gt;backup configuration precomputed&lt;/strong&gt;, stored and replicated to each controller which can apply immediately.&lt;/p&gt;

&lt;p&gt;Finally, Metron is able to fully inspect traffic at 40Gbps and 100Gbps with low latency outperforming state of the art current NFV like OpenBox and EC2.&lt;/p&gt;

&lt;h4 id=&quot;contributions-2&quot;&gt;Contributions&lt;/h4&gt;
&lt;p&gt;A key point in Metron is that &lt;strong&gt;it cuts away all the expensive inter-core communication allowing a huge increase in overall performances&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In fact using smart tagging allows to very efficiently dispatch the packets to the right core thus eliminating the need of a dispatcher running on its own thread, this way some important work is relayed to the NIC.&lt;/p&gt;

&lt;p&gt;There are way to achieve this like “augmenting the NIC with a software layer” (EC2) or with a series of pipeline each one attributed to one core or with RSS flow hashing but none of these guarantees that the core receiving the packet will also be the one processing it.&lt;/p&gt;

&lt;p&gt;This is why &lt;strong&gt;for the first time Metron leverages the NIC capabilities&lt;/strong&gt;, offloading the traffic classification so that packets are tagged as soon as possible. (with SNF)&lt;/p&gt;

&lt;p&gt;About the statistic gathering throughout the network, instead of polling each device, adding delay and bandwidth and causing interrupts, Metron uses a smart approach called “&lt;em&gt;power of two random choices&lt;/em&gt;” where it actually just asks to two random devices and take the least loaded. These stats along with others from key locations allow Metron to &lt;strong&gt;dynamically scale resources&lt;/strong&gt;, duplicating instances of NFs and splitting flows among them.&lt;/p&gt;

&lt;h2 id=&quot;cloud-load-balancing&quot;&gt;&lt;strong&gt;Cloud load balancing&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The paper &lt;a class=&quot;citation&quot; href=&quot;#ananta&quot;&gt;[4]&lt;/a&gt; proposes &lt;strong&gt;ANANTA&lt;/strong&gt;, a Layer 4 load balancing and NAT software architecture able to satisfy multi tenant cloud requirements scaling-out web services and running on commodity servers.&lt;/p&gt;

&lt;p&gt;It has been proposed to achieve that level of reliability, scaling and performance and isolation needed in today cloud’s datacenter.  Essentially &lt;strong&gt;Ananta divides the load balancer into a decentralized horizontally scalable data plane and a consensus-based reliable control plane&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This architecture has been used by Microsoft Azure cloud with success &lt;strong&gt;achieving more than 100Gbps throughput for a single IP&lt;/strong&gt; and an aggregated one reaching 1Tbps.&lt;/p&gt;

&lt;p&gt;There are three tiers in the data plane: first the packet arrives at routers, here via ECMP (L3) load is randomly distributed to &lt;em&gt;MUX&lt;/em&gt; devices, second MUX provide a connection-level (L4) load balancing spreading load to the servers, third the virtual switch in each server provide stateful NAT.&lt;/p&gt;

&lt;p&gt;There is a controller &lt;strong&gt;Ananta Manager&lt;/strong&gt; (AM), one or more &lt;strong&gt;Multiplexer&lt;/strong&gt; (MUX) and the &lt;strong&gt;Host Agent&lt;/strong&gt; (HA) in each server. Each server has assigned a private Direct IP (DIP) and each service a Public Virtual IP (VIP).&lt;/p&gt;

&lt;figure&gt;
    &lt;img style=&quot;display: block; margin: auto; width: 80%; padding-top:25px&quot; src=&quot;/assets/ananta.png&quot; /&gt;
&lt;figcaption&gt;Figure 11. Ananta Data Plane Tiers. Figure from &lt;a href=&quot;https://www.semanticscholar.org/paper/Ananta%3A-cloud-scale-load-balancing-Patel-Bansal/5b999d36d5230eca01532b357c7cf338a5e0d641/figure/0&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
    
&lt;/figure&gt;

&lt;p&gt;The Manager is critical for configuring Host Agents and MUXs but also because provides port allocation for outbound SNAT to the Host Agent. The &lt;strong&gt;MUX is a BGP speaker&lt;/strong&gt; which advertise itself to the Manager for routes towards its DIPs. And the Host Agent manages DSR and NAT along with FastPath and VM health monitoring.&lt;/p&gt;

&lt;h4 id=&quot;contributions-3&quot;&gt;Contributions&lt;/h4&gt;
&lt;p&gt;The paper identifies the most important requirements and overcome them introducing Ananta, being able to provide cloud-scale solution for load balancing.&lt;/p&gt;

&lt;p&gt;A key difference from Ananta and other load balancer systems is that here &lt;strong&gt;Data/Control plane processing is in part offloaded to the end systems&lt;/strong&gt; relieving the network from load and more difficult state management.&lt;/p&gt;

&lt;p&gt;Ananta makes use of &lt;strong&gt;&lt;em&gt;Direct Server Return&lt;/em&gt;&lt;/strong&gt; or &lt;strong&gt;DSR&lt;/strong&gt; to relieve Load balancers (MUX) from the useless work of processing the packets back to destination. Indeed the packet leaves the Host Agent with the destination IP already set so that it can reach the client without passing through the MUX.&lt;/p&gt;

&lt;figure&gt;
    &lt;img style=&quot;display: block; margin: auto; width: 60%; padding-top:25px&quot; src=&quot;/assets/ananta2.png&quot; /&gt;
&lt;figcaption&gt;Figure 12. The Ananta Architecture. Ananta consists of three components — Ananta Manager, Ananta Mux and Host Agent. Each component is independently scalable. Manager coordinates state across Agents and Muxes. Mux is responsible for packet forwarding for inbound packets. Agent implements NAT, which allows all outbound traffic to bypass Mux. Agents are co-located with destination servers. Figure from &lt;a href=&quot;https://www.semanticscholar.org/paper/Ananta%3A-cloud-scale-load-balancing-Patel-Bansal/5b999d36d5230eca01532b357c7cf338a5e0d641/figure/4&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
    
&lt;/figure&gt;

&lt;p&gt;Furthermore using a Virtual IP allows easy enforcement and management of ACL lists and make it easier to handle disaster recovery or upgrades since it can be dynamically mapped to another instance. Ananta makes use of BGP between Manager and MUXs which allows automatic failure detection and recovery.&lt;/p&gt;

&lt;p&gt;Importantly, the network scales as it increases because much work is done by hosts and MUX are horizontally scalable.&lt;/p&gt;

&lt;h2 id=&quot;connectivity-recovery-directly-in-the-data-plane&quot;&gt;&lt;strong&gt;Connectivity recovery directly in the Data-Plane&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The paper &lt;a class=&quot;citation&quot; href=&quot;#blink&quot;&gt;[5]&lt;/a&gt; proposes &lt;strong&gt;BLINK&lt;/strong&gt; a completely new approach for dealing with &lt;strong&gt;network failures&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;It recovers from failures leveraging TCP signals directly within the data plane  with no expensive calls to the control plane&lt;/strong&gt;. It does take advantage from the key intuition that TCP flows experience a predictable behavior in case of disruption (retransmission).&lt;/p&gt;

&lt;p&gt;BLINK first &lt;strong&gt;selects TCP flows to track&lt;/strong&gt; (limited amount due to memory constraints) then &lt;strong&gt;detect major disruptions&lt;/strong&gt; (if majority of flows experience retransmission) and in the end &lt;strong&gt;recover connectivity&lt;/strong&gt; (mainly applying backup path) all in the data plane.&lt;/p&gt;

&lt;p&gt;BLINK is able to recover in &lt;strong&gt;sub-second&lt;/strong&gt; through fast rerouting and quick activation of backup path and is thus able to solve problem of the long convergence time for &lt;strong&gt;remote&lt;/strong&gt; failures (frequent and slow to repair) which used to invoke the control plane to let the topology converge (BGP updates).&lt;/p&gt;

&lt;p&gt;Challenges to achieve this are multiple and between them we see memory constraints (sampling), rerouting must apply only on major disruptions and must ignore temporary or casual retransmissions (noisy signals) and the impossibility to know the root cause of those failures (forwarding correctness).&lt;/p&gt;

&lt;p&gt;BLINK is implemented in Python and tested on a Tofino hardware switch and provide a good balance between detection and robustness to noisy signals offering on the average a fast sub-second recover. Importantly BLINK is &lt;strong&gt;able to be insensitive to normal congestion events&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id=&quot;contributions-4&quot;&gt;Contributions&lt;/h4&gt;
&lt;p&gt;The paper exposes a completely new approach to recover from failures directly in the data plane leveraging TCP signaling. In fact it introduces a new framework for fast rerouting (sub-seconds) for both local and &lt;em&gt;remote&lt;/em&gt; failures.&lt;/p&gt;

&lt;p&gt;BLINK &lt;strong&gt;avoids memory problems&lt;/strong&gt; with a &lt;em&gt;Flow selector&lt;/em&gt; which keeps track of the 64 most active flows evicting the non active, and also the active ones after a certain amount of time.&lt;/p&gt;

&lt;p&gt;Blink importantly allows to &lt;em&gt;quickly recover&lt;/em&gt; from loops and blackholes by &lt;strong&gt;checking connectivity of each backup path before and after being applied&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Blinks leverage TCP congestion knowledge about RTO to set the right timer (default 2 sec) for flows eviction and avoid noisy signals causing useless temporary re-routing.&lt;/p&gt;

&lt;p&gt;BLINK make use of a logic &lt;em&gt;pipeline&lt;/em&gt; for processing the various stages which are Selection, Detection and ReRouting.&lt;/p&gt;

&lt;h2 id=&quot;here-link-to-part-1&quot;&gt;&lt;strong&gt;&lt;a href=&quot;/2019/network/sdn/software-defined-networking-introduction/&quot;&gt;Here link to PART 1&lt;/a&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;references&quot;&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/h2&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;simple&quot;&gt;[1]Z. A. Qazi, C.-C. Tu, L. Chiang, R. Miao, V. Sekar, and M. Yu, “SIMPLE-fying Middlebox Policy Enforcement Using SDN,” in &lt;i&gt;Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM&lt;/i&gt;, New York, NY, USA, 2013, pp. 27–38, doi: 10.1145/2486001.2486022 [Online]. Available at: http://doi.acm.org/10.1145/2486001.2486022&lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;midd-outsourc&quot;&gt;[2]J. Sherry, S. Hasan, C. Scott, A. Krishnamurthy, S. Ratnasamy, and V. Sekar, “Making Middleboxes Someone else’s Problem: Network Processing As a Cloud Service,” in &lt;i&gt;Proceedings of the ACM SIGCOMM 2012 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication&lt;/i&gt;, New York, NY, USA, 2012, pp. 13–24, doi: 10.1145/2342356.2342359 [Online]. Available at: http://doi.acm.org/10.1145/2342356.2342359&lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;metron&quot;&gt;[3]G. P. Katsikas, T. Barbette, D. Kostić, R. Steinert, and G. Q. M. Jr., “Metron: NFV Service Chains at the True Speed of the Underlying Hardware,” in &lt;i&gt;15th USENIX Symposium on Networked Systems Design and Implementation (NSDI 18)&lt;/i&gt;, Renton, WA, 2018, pp. 171–186 [Online]. Available at: https://www.usenix.org/conference/nsdi18/presentation/katsikas&lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;ananta&quot;&gt;[4]P. Patel &lt;i&gt;et al.&lt;/i&gt;, “Ananta: Cloud Scale Load Balancing,” &lt;i&gt;ACM SIGCOMM Computer Communication Review&lt;/i&gt;, vol. 43, Aug. 2013, doi: 10.1145/2486001.2486026. &lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;blink&quot;&gt;[5]T. Holterbach, E. C. Molero, M. Apostolaki, A. Dainotti, S. Vissicchio, and L. Vanbever, “Blink: Fast Connectivity Recovery Entirely in the Data Plane,” in &lt;i&gt;16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19)&lt;/i&gt;, Boston, MA, 2019, pp. 161–176 [Online]. Available at: https://www.usenix.org/conference/nsdi19/presentation/holterbach&lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;
</description>
        <pubDate>Fri, 19 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://carloalbertoscola.it//2019/network/sdn/network-function-virtualization-cloud-load-balancing-middleboxes/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2019/network/sdn/network-function-virtualization-cloud-load-balancing-middleboxes/</guid>
        
        
        <category>network</category>
        
        <category>sdn</category>
        
      </item>
    
      <item>
        <title>An introduction to Software Defined Networking</title>
        <description>&lt;h1 class=&quot;no_toc&quot; id=&quot;the-new-way-to-do-networking-with-sdn&quot;&gt;&lt;strong&gt;&lt;center&gt;The &quot;new&quot; way to do networking with SDN&lt;/center&gt;&lt;/strong&gt;&lt;/h1&gt;
&lt;h2 class=&quot;no_toc&quot; id=&quot;sdn-applications-analysis-and-scaling-&quot;&gt;&lt;strong&gt;&lt;center&gt;SDN applications, analysis and scaling &lt;/center&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 class=&quot;no_toc&quot; id=&quot;-research-papers-review-and-summary-&quot;&gt;&lt;center&gt; Research papers review and summary. &lt;/center&gt;&lt;/h3&gt;
&lt;h3 class=&quot;no_toc&quot; id=&quot;-part-1---here-link-to-part-2&quot;&gt;&lt;center&gt; PART 1 - &lt;a href=&quot;/2019/network/sdn/network-function-virtualization-cloud-load-balancing-middleboxes/&quot;&gt;Here link to PART 2&lt;/a&gt;&lt;/center&gt;&lt;/h3&gt;
&lt;p&gt;In &lt;strong&gt;&lt;a href=&quot;/2019/network/sdn/python/software-defined-networking-nfv-example-with-pox-click-openflow/&quot;&gt;this post&lt;/a&gt;&lt;/strong&gt; there is a practical step-by-step project with POX SDN, OpenFlow, Click and NFV.&lt;/p&gt;

&lt;h3 class=&quot;no_toc&quot; id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h3&gt;
&lt;div id=&quot;inline_toc&quot;&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#the-arrival-of-sdn-and-openflow&quot; id=&quot;markdown-toc-the-arrival-of-sdn-and-openflow&quot;&gt;&lt;strong&gt;The arrival of SDN and OpenFlow&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions&quot; id=&quot;markdown-toc-contributions&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-to-implement-sdn&quot; id=&quot;markdown-toc-how-to-implement-sdn&quot;&gt;&lt;strong&gt;How to implement SDN?&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions-1&quot; id=&quot;markdown-toc-contributions-1&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-to-test-and-debug-sdn-applications&quot; id=&quot;markdown-toc-how-to-test-and-debug-sdn-applications&quot;&gt;&lt;strong&gt;How to test and debug SDN applications?&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#header-space-analysis&quot; id=&quot;markdown-toc-header-space-analysis&quot;&gt;&lt;strong&gt;Header Space Analysis&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions-2&quot; id=&quot;markdown-toc-contributions-2&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#a-nice-way-to-test-openflow-applications&quot; id=&quot;markdown-toc-a-nice-way-to-test-openflow-applications&quot;&gt;&lt;strong&gt;A NICE Way to Test OpenFlow Applications&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions-3&quot; id=&quot;markdown-toc-contributions-3&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-to-scale-sdn-applications-at-large&quot; id=&quot;markdown-toc-how-to-scale-sdn-applications-at-large&quot;&gt;&lt;strong&gt;How to scale SDN applications at large?&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions-4&quot; id=&quot;markdown-toc-contributions-4&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#the-sdx---software-defined-internet-exchange&quot; id=&quot;markdown-toc-the-sdx---software-defined-internet-exchange&quot;&gt;&lt;strong&gt;The SDX - Software Defined Internet Exchange&lt;/strong&gt;&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#contributions-5&quot; id=&quot;markdown-toc-contributions-5&quot;&gt;Contributions&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#here-link-to-part-2&quot; id=&quot;markdown-toc-here-link-to-part-2&quot;&gt;&lt;strong&gt;Here link to PART 2&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references&quot; id=&quot;markdown-toc-references&quot;&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;hr /&gt;

&lt;div&gt;
&lt;span class=&quot;read-time-txt&quot;&gt;Reading time:&lt;/span&gt;
&lt;span class=&quot;read-time-val&quot;&gt;


  12 mins

&lt;/span&gt;
	 
&lt;p class=&quot;read-time-date&quot;&gt;
	&lt;script&gt;
	var today = new Date();
	weekday = [&quot;Sunday&quot;, &quot;Monday&quot;,&quot;Tuesday&quot;, &quot;Wednesday&quot;,&quot;Thursday&quot;, &quot;Friday&quot;,&quot;Saturday&quot;];
	mlist = [ &quot;January&quot;, &quot;February&quot;, &quot;March&quot;, &quot;April&quot;, &quot;May&quot;, &quot;June&quot;, &quot;July&quot;, &quot;August&quot;, &quot;September&quot;, &quot;October&quot;, &quot;November&quot;, &quot;December&quot; ];
	var time = today.getHours() + &quot;:&quot; + today.getMinutes();
	var d = weekday[today.getDay()] + &quot; &quot; +today.getDate() + &quot; &quot; + mlist[today.getMonth()] + &quot; &quot; + today.getFullYear();
	document.write(d + &quot;  &quot; + time);
	&lt;/script&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;h3 id=&quot;the-arrival-of-sdn-and-openflow&quot;&gt;&lt;strong&gt;The arrival of SDN and OpenFlow&lt;/strong&gt;&lt;/h3&gt;
&lt;figure&gt;
    &lt;img style=&quot;display: block; margin: auto; width: 80%; padding-top:25px&quot; src=&quot;/assets/sdn-draw.jpeg&quot; /&gt;
    &lt;figcaption&gt;Figure from &lt;a href=&quot;https://www.starwindsoftware.com/blog/how-to-deploy-and-manage-software-defined-networking-using-scvmm-2016-part-iii&quot;&gt;here &lt;/a&gt;&lt;/figcaption&gt;
    
&lt;/figure&gt;
&lt;p&gt;Improving networks protocols and deploying new features or applications is very hard on traditional networks. The time needed for designing to implementing changes is extremely long and costly. Today network functions can be virtualized and aggregated into one single machine acting as &lt;em&gt;controller&lt;/em&gt;. The control plane on routers and switches is decoupled from the data plane and put into another device. Here the concept of SDNs comes with many pros: higher &lt;em&gt;flexibility&lt;/em&gt;, better &lt;em&gt;scaling&lt;/em&gt;, and &lt;em&gt;ease of implementation and maintenance&lt;/em&gt; from developers thus reducing cost for hardware. The key idea is that &lt;strong&gt;network devices now only implements basic primitives&lt;/strong&gt; and constantly talk with the &lt;strong&gt;Domain Controller&lt;/strong&gt; to push statistics and pull routing information. The protocol utilized to push and set rules into the “dumb” switches is called &lt;strong&gt;OpenFlow&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In the paper  &lt;a class=&quot;citation&quot; href=&quot;#onix&quot;&gt;[1]&lt;/a&gt;, jumping back into the 2010, &lt;strong&gt;&lt;em&gt;ONIX&lt;/em&gt;&lt;/strong&gt; is explained as a &lt;em&gt;control platform&lt;/em&gt; exposing simple API and introducing a &lt;em&gt;Network Information Base (&lt;strong&gt;NIB&lt;/strong&gt;)&lt;/em&gt; similar to the RIB. There are four basic components in ONIX: the &lt;em&gt;physical infrastructure&lt;/em&gt; (switches and routers), &lt;em&gt;connectivity infrastructure&lt;/em&gt; (used as a management network), &lt;em&gt;Onix distributed system&lt;/em&gt; (single instance / cluster) and the &lt;em&gt;Control logic&lt;/em&gt; (implemented on top of API) and failures can happen on each one of these parts. It is built on &lt;em&gt;NOX&lt;/em&gt; and distributed among multiple servers. The API allow read/write data object &lt;em&gt;state&lt;/em&gt; into/from the NIB which is the main focus point of the system.&lt;/p&gt;

&lt;figure&gt;
    &lt;img style=&quot;display: block; margin: auto; width: 80%; padding-top:25px&quot; src=&quot;/assets/onix.png&quot; /&gt;
    &lt;figcaption&gt;Figure 1. Onix Infrastructure - from &lt;a href=&quot;https://muratbuffalo.blogspot.com/2010/12/onix-distributed-control-platform-for.html&quot;&gt;here &lt;/a&gt;&lt;/figcaption&gt;
    
&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;The NIB is the complete network graph&lt;/strong&gt; containing each device, link, routes and attributes all put into &lt;em&gt;Entities&lt;/em&gt;.&lt;br /&gt;
Onix allows easy scaling through &lt;strong&gt;Partitioning and Aggregation&lt;/strong&gt;, replicating the controller, making switches only contact a subset of them and making each controller manage only a subset of the whole NIB.&lt;/p&gt;

&lt;p&gt;When there is a change in the NIB, it will translate the change into an OpenFlow message and then push to the affected device. For this, import/export modules sit behind the NIB waiting for polls or changes.&lt;/p&gt;

&lt;p&gt;Another feature of ONIX is the possibility to store data in two different ways, through a SQL database for stable states and to a DHT for dynamic states.&lt;/p&gt;

&lt;h4 id=&quot;contributions&quot;&gt;Contributions&lt;/h4&gt;
&lt;p&gt;ONIX doesn’t introduce anything totally new, in fact it derives some work from &lt;em&gt;Ethane&lt;/em&gt;, &lt;em&gt;SANE&lt;/em&gt;, &lt;em&gt;RCP&lt;/em&gt; and &lt;em&gt;NOX&lt;/em&gt;. But those did not address reliability and flexibility as ONIX does but instead presented the idea of a physically separated control plane.&lt;/p&gt;

&lt;p&gt;Indeed among the top contributions of ONIX, we can see the use of &lt;strong&gt;general APIs and flexible distribution primitives&lt;/strong&gt; which allow designers to work on a pre-tested and established base and implement control application with all the flexibility they need.&lt;/p&gt;

&lt;p&gt;APIs allow read/write state to any element in the network which corresponds to data-objects in the NIB. Since switches have narrower requirements along with a limited quantity of RAM and CPU, most of the work can be done on platforms that don’t have such limitations such as the Domain Controller.&lt;/p&gt;

&lt;p&gt;Here ONIX presents two way of storing state information: a &lt;strong&gt;persistent SQL transactional database&lt;/strong&gt; for slowly changing state and a &lt;strong&gt;memory-only DHT&lt;/strong&gt; for dynamic and mostly inconsistent state. ONIX allow developers to choose their own trade-off, for example: more consistency and durability or more efficiency.&lt;/p&gt;

&lt;h2 id=&quot;how-to-implement-sdn&quot;&gt;&lt;strong&gt;How to implement SDN?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;SDNs application development does not offer great flexibility in terms of modularity which is instead the focus of the paper &lt;a class=&quot;citation&quot; href=&quot;#pyretic&quot;&gt;[2]&lt;/a&gt;. It introduces a new language and abstractions for &lt;strong&gt;building modular applications&lt;/strong&gt; on top of SDNs. &lt;strong&gt;&lt;em&gt;Pyretic&lt;/em&gt;&lt;/strong&gt; allows packets to be processed &lt;em&gt;sequentially&lt;/em&gt; or &lt;em&gt;concurrently&lt;/em&gt;, thus producing different results for different use cases. It gives developers great building blocks and &lt;em&gt;high-level policy functions&lt;/em&gt; with extreme shortness of code and readability. Physical switches can now be virtually merged into single devices (many-to-one) or instead single physical switches can be logically divided into multiple virtual switch handling different modules (one-to-many).&lt;/p&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width: 80%; padding-top:25px&quot; src=&quot;/assets/pyretic.png&quot; /&gt;
    &lt;figcaption&gt;Figure 2. Some primitive examples from Pyretic&lt;/figcaption&gt;
    
&lt;/figure&gt;
&lt;p&gt;Monitoring, Firewall and Load balancing examples are shown in the paper which use different features of the language like static policy language (called NetCore) which includes &lt;em&gt;primitive actions&lt;/em&gt; (drop, flood, passthrough ..), &lt;em&gt;predicates&lt;/em&gt; (act on subset of packets), &lt;em&gt;policies&lt;/em&gt; and &lt;em&gt;queries&lt;/em&gt;. 
In Pyretic, a policy receives a packet as input and returns a multiset of localized packets as output and packets in order to be processed need to be “lifted” from physical switches to the virtual instances. This up/down process is achieved with the use of &lt;strong&gt;virtual tags&lt;/strong&gt; and &lt;strong&gt;headers&lt;/strong&gt; specifying input/output ports and switches name. This allows developers to better abstract a &lt;strong&gt;derived&lt;/strong&gt; network from the &lt;strong&gt;underlying&lt;/strong&gt; one.
Finally the high level of abstraction provides an elegant mechanism to implement different networks topologies and writing self-contained modules.&lt;/p&gt;

&lt;h4 id=&quot;contributions-1&quot;&gt;Contributions&lt;/h4&gt;

&lt;p&gt;Software Defined Networking has limited support for modular components design and programming, in fact the paper target is to show and explain a new way of composing SDNs with multiple components. &lt;strong&gt;Modularity is the key&lt;/strong&gt;, it allows developers to not implement monolithic applications with API (like in ONIX) and just focus on high level policies. The paper presents two way of handling packets, a &lt;strong&gt;&lt;em&gt;sequential composition&lt;/em&gt;&lt;/strong&gt; and a &lt;strong&gt;&lt;em&gt;parallel composition&lt;/em&gt;&lt;/strong&gt;. It also proposes “Network object” which constrain the modules and allow information hiding and protection.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Pyretic Language&lt;/strong&gt; shown here is a step further in the development of SDNs with the concept of modular and extensible programming. Here the &lt;strong&gt;packets are represented as dictionaries&lt;/strong&gt;, and the addition of &lt;strong&gt;virtual headers&lt;/strong&gt; is made simple and allows fine-grained modularity and policy development.&lt;/p&gt;

&lt;p&gt;Other control platform such &lt;strong&gt;&lt;em&gt;NOX&lt;/em&gt;&lt;/strong&gt; used to offer low-level interfaces, but composition isolation and virtualization are plus added by Pyretic and programmers do not need to resolve conflicts by hand.&lt;/p&gt;

&lt;p&gt;Pyretic is able to build sophisticated controller applications for large networks with the use of a simple language as Python. Details about Pyretic here &lt;a class=&quot;citation&quot; href=&quot;#programming-with-pyretic&quot;&gt;[3]&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-to-test-and-debug-sdn-applications&quot;&gt;&lt;strong&gt;How to test and debug SDN applications?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Two papers go through the testing and debugging of SDN applications:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;“&lt;em&gt;Header Space Analysis: Static Checking For Networks&lt;/em&gt;”&lt;/li&gt;
  &lt;li&gt;“&lt;em&gt;A NICE Way to Test OpenFlow Applications&lt;/em&gt;”&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;header-space-analysis&quot;&gt;&lt;strong&gt;Header Space Analysis&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;In the old times network devices were very simple with just the role of forwarding packets, today there is a large number of protocols, encapsulation methods and policies to keep in mind. This makes debugging problems very hard and long to resolve and that is one reason why the paper &lt;a class=&quot;citation&quot; href=&quot;#hsa&quot;&gt;[4]&lt;/a&gt; exposes &lt;strong&gt;Header Space Analysis&lt;/strong&gt; framework for a &lt;strong&gt;static analysis&lt;/strong&gt; of production networks.&lt;/p&gt;

&lt;p&gt;The key idea is that the framework is protocol agnostic, allowing to test different environment with different header formats and syntax without reinventing the wheel. &lt;strong&gt;Hassel&lt;/strong&gt; doesn’t care about the semantic, it just matches series of {0,1} in the space &lt;em&gt;L&lt;/em&gt; of the packet headers, since the data part has been proven to be irrelevant for the calculations. With the use of &lt;strong&gt;transfer functions&lt;/strong&gt;, the framework is able to map, simulate and test the network for &lt;em&gt;forwarding loops&lt;/em&gt; (finite and infinite) and &lt;em&gt;configuration errors&lt;/em&gt;.&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width: 60%; padding-top:25px&quot; src=&quot;/assets/hsa1.png&quot; /&gt;
&lt;figcaption&gt;Figure 3. (a) Changes to a flow as it passes through two boxes with transfer function TA and TB . (b) Composing transfer functions to model end to end behavior of a network. Figure from &lt;a href=&quot;https://www.semanticscholar.org/paper/Header-Space-Analysis%3A-Static-Checking-for-Networks-Kazemian-Varghese/19114b7a2f5243a47e80590cc11a2d8ec5b96308&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The framework &lt;strong&gt;geometrically models network boxes and applications&lt;/strong&gt; like firewall and NAT with transfer functions which operates through the use of algebra &lt;strong&gt;primitive operations&lt;/strong&gt; (intersection, union, complementation and difference). Loops can be detected &lt;strong&gt;injecting packet&lt;/strong&gt; in the network and looking if the same packet come back to the injection port. &lt;strong&gt;Static analysis&lt;/strong&gt; can be applied for reachability checking to verify if packets can logically reach a destination and if a destination can possibly receive packet from a determined source using the &lt;em&gt;range inverse&lt;/em&gt; computation.&lt;/p&gt;

&lt;p&gt;Hassel is implemented in Python 2.6 along with a parser for Cisco IOS configuration output that &lt;strong&gt;automatically generate transfer functions and model of the router&lt;/strong&gt;. The implementation also employs optimizations that allowed a 19x to 400x speed increment.&lt;/p&gt;

&lt;p&gt;Tests on the Stanford network showed that the tool has been of great usefulness in detecting loops and configuration mistakes.&lt;/p&gt;

&lt;h4 id=&quot;contributions-2&quot;&gt;Contributions&lt;/h4&gt;

&lt;p&gt;The idea of &lt;strong&gt;&lt;em&gt;transfer functions&lt;/em&gt;&lt;/strong&gt; used by Hassel is very similar to the ASE Mapping in axiomatic routing. Here instead, Hassel does not try to understand protocols and packet headers, &lt;strong&gt;it treats everything like a point {0,1} in space large &lt;em&gt;L&lt;/em&gt;&lt;/strong&gt;, being &lt;em&gt;L&lt;/em&gt; the header length. In fact Hassel introduces different new terms to define a domain for the analysis like Header and Network Space along with the transfer functions. The Transfer functions “move” packets from one port to another, “transforming” the packet at each step.&lt;/p&gt;

&lt;p&gt;Another important feature is the possibility to &lt;em&gt;slice&lt;/em&gt; the network in different part (like MPLS, VLANs and FlowVisor), and test each one for security isolation and leaks. This is done by detecting if a possible function output of a domain ends up in another un-allowed domain, for example if a packet from one VLAN can pass to another VLAN while processing and rewriting its headers.&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width: 60%; padding-top:25px&quot; src=&quot;/assets/hsa-slice.png&quot; /&gt;
&lt;figcaption&gt;Figure 4.  Detecting slice leakage. Although slice a and b have disjoint slice reservation on S1 and S2, but slice a’s reservation on S1 can leak to slice b’s reservation os S2 after it is rewritten by slice a’s transfer function rules. Figure from &lt;a href=&quot;https://www.semanticscholar.org/paper/Header-Space-Analysis%3A-Static-Checking-for-Networks-Kazemian-Varghese/19114b7a2f5243a47e80590cc11a2d8ec5b96308&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;A great contribution of Hassel is the fact that it made it &lt;strong&gt;easier to spot network violations&lt;/strong&gt; with network transfer function in a static and non-risky way. In fact the implementation was proven to find real mistakes in the Stanford network in a considerable short time.&lt;/p&gt;

&lt;h4 id=&quot;a-nice-way-to-test-openflow-applications&quot;&gt;&lt;strong&gt;A NICE Way to Test OpenFlow Applications&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;With the increasing adoption of SDN technology, asynchronous and distributed systems become difficult to test for certain class of bugs. This is where &lt;strong&gt;NICE&lt;/strong&gt; or &lt;em&gt;No bugs In Controller Execution&lt;/em&gt; tries to fill the gap &lt;a class=&quot;citation&quot; href=&quot;#nice&quot;&gt;[5]&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;NICE is a tool for testing &lt;strong&gt;unmodified controller programs&lt;/strong&gt; on the NOX platform. It makes use of two important techniques: &lt;strong&gt;model checking&lt;/strong&gt; and &lt;strong&gt;symbolic execution&lt;/strong&gt;.&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width: 60%; padding-top:25px&quot; src=&quot;/assets/nice1.png&quot; /&gt;
&lt;figcaption&gt;Figure 5. Given an OpenFlow program, a network topology, and correctness properties, NICE performs a statespace search and outputs traces of property violations. Figure from &lt;a href=&quot;https://www.semanticscholar.org/paper/A-NICE-Way-to-Test-OpenFlow-Applications-Canini-Venzano/04b319357d6bab89ec9575f4b044d7609aa4296a/figure/0&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In order to test an app, it is needed to &lt;em&gt;model&lt;/em&gt; the system acquiring the possible &lt;em&gt;states&lt;/em&gt; which could be infinite. &lt;strong&gt;Model checking gather all the possible states&lt;/strong&gt;, but being the output too large, &lt;strong&gt;symbolic execution is coupled to test only the relevant code paths&lt;/strong&gt;. Model checking explore system states  and model the execution with &lt;em&gt;components&lt;/em&gt;, &lt;em&gt;channels&lt;/em&gt;, &lt;em&gt;components states&lt;/em&gt; and &lt;em&gt;transitions&lt;/em&gt;. It define “class of packets” and chooses a “representative packet” to be the tester for that specific state case, defining this way different &lt;em&gt;domain specific search strategies&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;NICE sends packet at different events interleaving, simulating as close as possible the real world execution scenario. Controller programs are viewed as set of event handlers that create transitions (changes in global var settings). Symbolic execution instead does not model the system space but rather focuses on &lt;strong&gt;identifying relevant inputs&lt;/strong&gt; but it’s still not sufficient “per se”.&lt;/p&gt;

&lt;p&gt;The combination of the two is what allows NICE to scale and uncover tricky bugs in potentially interminable possible states. If a transition violates a certain correctness property (these are configurable), than NICE records the state and log the error.&lt;/p&gt;

&lt;h4 id=&quot;contributions-3&quot;&gt;Contributions&lt;/h4&gt;
&lt;p&gt;A significant problem in SDN applications is the &lt;strong&gt;delay on rule install&lt;/strong&gt; across different switches which &lt;strong&gt;cause unintended behavior&lt;/strong&gt; and performance degradation. Challenges that NICE try to solve are in the range of large space of inputs like switches states, input packets and event ordering.&lt;/p&gt;

&lt;figure&gt;
&lt;img style=&quot;display: block; margin: auto; width: 60%; padding-top:25px&quot; src=&quot;/assets/nice.png&quot; /&gt;
&lt;figcaption&gt;Figure 6. An example of OpenFlow network traversed by a packet. In a plausible scenario, due to delays between controller and switches, the packet does not encounter an installed rule in the second switch. Figure from &lt;a href=&quot;https://www.semanticscholar.org/paper/A-NICE-Way-to-Test-OpenFlow-Applications-Canini-Venzano/04b319357d6bab89ec9575f4b044d7609aa4296a/figure/0&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;An important contribution of NICE is its ability to &lt;strong&gt;generate streams of packets depending on controller state&lt;/strong&gt; in order to test the program and uncover forwarding loops and black holes. Its important to note that NICE relieves work from the developer, asking only to provide network topology and hosts.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NICE couples symbolic execution with model checking in order to lower the number of states and focus on the ones that can create meaningful transitions.&lt;/strong&gt; This allow to test applications without worrying about the huge system state space scalability problems. Furthermore NICE provides a set of &lt;em&gt;correctness properties&lt;/em&gt; with their own testing implementation which allows developers to quickly test and build custom modules.&lt;/p&gt;

&lt;p&gt;In fact NICE has proven to find different class of bugs in standard unmodified controller programs.&lt;/p&gt;

&lt;h2 id=&quot;how-to-scale-sdn-applications-at-large&quot;&gt;&lt;strong&gt;How to scale SDN applications at large?&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;OpenFlow imposes &lt;strong&gt;excessive overheads&lt;/strong&gt; on the controller when it comes to &lt;em&gt;high performance networks&lt;/em&gt;, thing that introduces unacceptable latencies and restricts system performances. The visibility over all the flows is simply un-achievable in High Performance networks. &lt;strong&gt;Openflow is inherently not scalable&lt;/strong&gt; and its design has two steps that involve the controller and create too much heavy load on it: &lt;em&gt;flows setup&lt;/em&gt; and &lt;em&gt;statistic gathering&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The paper exposes &lt;strong&gt;&lt;em&gt;DevoFlow&lt;/em&gt;&lt;/strong&gt; &lt;a class=&quot;citation&quot; href=&quot;#devoflow&quot;&gt;[6]&lt;/a&gt;, which is a slightly modified version of OpenFlow which aims to overcome such disadvantages. In fact it gives back to routers the forwarding decisions on most flows. 
Paper shows an analysis of trade-offs between centralized management and costs, and shows DevoFlows new mechanisms. &lt;strong&gt;Its goal is to keep as many flow entry in data plane as possible&lt;/strong&gt; (passing on control plane is expensive), while always maintaining enough visibility over the network.&lt;/p&gt;

&lt;p&gt;Central control gives a lot of good points like: &lt;em&gt;near optimal traffic management&lt;/em&gt;, &lt;em&gt;simplified policy development&lt;/em&gt; and simplicity and future-proof of switches but it creates overhead both in hardware resources, communication load and delay and latency which become the bottleneck.&lt;/p&gt;

&lt;p&gt;Devoflow introduces &lt;em&gt;rule cloning&lt;/em&gt; and &lt;em&gt;local actions&lt;/em&gt; which aims to relieves TCAM usage and controller overload. Also, multipath is supported with little difference from ECMP, here the paths are not constrained to be of the same cost to be chosen.&lt;/p&gt;

&lt;p&gt;Finally evaluations shows that DevoFlow can improve throughput of 32% with Clos and 55% with HyperX networks which is a great increase .&lt;/p&gt;

&lt;h4 id=&quot;contributions-4&quot;&gt;Contributions&lt;/h4&gt;
&lt;p&gt;The important takeaway from DevoFlow is the fact to &lt;strong&gt;give back to routers routing decision&lt;/strong&gt; on most of the flows called &lt;em&gt;microflows&lt;/em&gt; while only the significant ones, the &lt;em&gt;elephant flows&lt;/em&gt; are managed by the controller.&lt;/p&gt;

&lt;p&gt;Paper shows pro and cons of traditional OpenFlow centralized management and compares with DevoFlow devolving control and statistic collection. Here its important to point out the &lt;strong&gt;huge difference in bandwidth&lt;/strong&gt; between line card speed and ASICs-CPUs which is therefore limited to 17Mbps compared to 300Gbps of the line card.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stats gathering and flow setup compete for the limited bandwidth.&lt;/strong&gt; DevoFlows introduces &lt;em&gt;rule cloning&lt;/em&gt; in order to augment action of wildcard rules, saving them to the data plane thus relieving TCAM memory. &lt;strong&gt;Hedera&lt;/strong&gt; consider 5 secs to be the good pull time but for HPN it must be less than 500ms. &lt;strong&gt;Maestro&lt;/strong&gt; multi-thread controller can install rules twice as fast than NOX but DevoFlow introduces different statistic collection mechanisms like &lt;em&gt;sampling&lt;/em&gt;, &lt;em&gt;triggers&lt;/em&gt; and &lt;em&gt;approximation counters&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Ultimately DevoFlows uses &lt;strong&gt;&lt;em&gt;oblivious routing&lt;/em&gt;&lt;/strong&gt; which distributes fairly path probability in correlation of the link bandwidth, for example two links A (10Gbps) and B (1Gbps) will have different probability of being chosen, 10/11 for A and 1/11 for B, which is the exact perfect balancing.&lt;/p&gt;

&lt;p&gt;In fact it was showed to achieve “94% of the throughput that dynamic routing does on the worst case”.&lt;/p&gt;

&lt;h2 id=&quot;the-sdx---software-defined-internet-exchange&quot;&gt;&lt;strong&gt;The SDX - Software Defined Internet Exchange&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;One of the reason this paper is trying to address is the limited way of todays network of being capable of forwarding packets. In fact, it is &lt;strong&gt;based on destination IP prefixes&lt;/strong&gt; which does not offer flexibility and functionalities like a more useful matching towards header fields or BGP attributes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Software defined Internet Exchange&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;(SDX)&lt;/em&gt;&lt;/strong&gt; &lt;a class=&quot;citation&quot; href=&quot;#sdx&quot;&gt;[7]&lt;/a&gt; is a good solution to the problem, allowing peers to run SDN application, ensuring system scalability and avoiding BGP routes conflicts. Indeed paper addresses major problems of BGP like the one mentioned, a difficult and indirect way of express policies (AS path, local pref, etc) and the impossibility to have more control over end-end flows instead of just neighbors.&lt;/p&gt;

&lt;figure&gt;
    &lt;img style=&quot;display: block; margin: auto; width: 100%; padding-top:25px&quot; src=&quot;/assets/sdx.png&quot; /&gt;
&lt;figcaption&gt;Figure 7. SDX programming abstractions. Figure from &lt;a href=&quot;https://www.semanticscholar.org/paper/SDX%3A-a-software-defined-internet-exchange-Gupta-Vanbever/1942aff3bb24d4ff9c1e8688b1104a767f0bc346/figure/0&quot;&gt;here &lt;/a&gt; &lt;/figcaption&gt;
    
&lt;/figure&gt;

&lt;p&gt;Furthermore the approach &lt;strong&gt;must be scalable&lt;/strong&gt;, &lt;strong&gt;deployable&lt;/strong&gt; and providing a &lt;strong&gt;good programming abstraction&lt;/strong&gt;. SDX also provide TE inbound support, at the central location AS can install rules and control traffic according to IP/port.&lt;/p&gt;

&lt;p&gt;Anycast is supported for load balancing and SDX can also redirect flows to middleboxes when possible DOS are detected. &lt;strong&gt;Pyretic&lt;/strong&gt; is the language used to write policies, and SDX works by gathering them from ASs, augmenting and then translating into flow rules. The process is multi-stage and involves a &lt;strong&gt;route server&lt;/strong&gt; which actually calculate best path for each prefix and re-advertise the routes. Augmenting policies involves an explosion in size, but it can be largely reduced by grouping prefixes into &lt;strong&gt;FEC&lt;/strong&gt; and tagging different type of traffic directly on Border Routers.&lt;/p&gt;

&lt;h4 id=&quot;contributions-5&quot;&gt;Contributions&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;The main goal of SDX is to provide each participant (physical or remote) the illusion of a SDN switch&lt;/strong&gt; which simplifies policies creation and management in multiple ways.&lt;/p&gt;

&lt;p&gt;The paper also identifies class of applications that can be deployed one of which is “&lt;em&gt;Application specific peering&lt;/em&gt;” that allows ASs to exchange traffic only for a subset of application classes. ex (only youtube traffic) and SDX easily integrate this by installing rules for group of flows.&lt;/p&gt;

&lt;p&gt;Importantly SDX allow ASs &lt;strong&gt;isolation&lt;/strong&gt; while aggregating participants policies so that each one can only act on  its own traffic. SDX also ensure consistency among BGP routes with the use of filters and no loops can be created.&lt;/p&gt;

&lt;p&gt;The paper also points out that prefixes tend to be stable , BGP routes only affects small part of forwarding table and BGP route changes occur in bursts and are followed by long periods. These aspects have greatly helped to better think and improve the policy compilation processes.&lt;/p&gt;

&lt;h2 id=&quot;here-link-to-part-2&quot;&gt;&lt;strong&gt;&lt;a href=&quot;/2019/network/sdn/network-function-virtualization-cloud-load-balancing-middleboxes/&quot;&gt;Here link to PART 2&lt;/a&gt;&lt;/strong&gt;&lt;/h2&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;references&quot;&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/h2&gt;

&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;onix&quot;&gt;[1]T. Koponen, M. Casado, and N. Gude, “Onix: A distributed control platform for large-scale production networks,” &lt;i&gt;Proceedings of the 9th USENIX Symposium on Operating Systems Design and Implementation&lt;/i&gt;, Jan. 2010. &lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;pyretic&quot;&gt;[2]C. Monsanto, J. Reich, N. Foster, J. Rexford, and D. Walker, “Composing Software Defined Networks,” in &lt;i&gt;10th USENIX Symposium on Networked Systems Design and Implementation (NSDI 13)&lt;/i&gt;, Lombard, IL, 2013, pp. 1–13 [Online]. Available at: https://www.usenix.org/conference/nsdi13/technical-sessions/presentation/monsanto&lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;programming-with-pyretic&quot;&gt;[3]J. Reich, C. Monsanto, N. Foster, J. Rexford, and D. Walker, “Modular SDN programming with pyretic,” &lt;i&gt;USENIX Login&lt;/i&gt;, vol. 38, pp. 128–134, Jan. 2013. &lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;hsa&quot;&gt;[4]P. Kazemian, G. Varghese, and N. McKeown, “Header Space Analysis: Static Checking for Networks,” in &lt;i&gt;Presented as part of the 9th USENIX Symposium on Networked Systems Design and Implementation (NSDI 12)&lt;/i&gt;, San Jose, CA, 2012, pp. 113–126 [Online]. Available at: https://www.usenix.org/conference/nsdi12/technical-sessions/presentation/kazemian&lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;nice&quot;&gt;[5]M. Canini, D. Venzano, P. Peresini, D. Kostic, and J. Rexford, “A NICE Way to Test OpenFlow Applications,” in &lt;i&gt;Presented as part of the 9th USENIX Symposium on Networked Systems Design and Implementation (NSDI 12)&lt;/i&gt;, San Jose, CA, 2012, pp. 127–140 [Online]. Available at: https://www.usenix.org/conference/nsdi12/technical-sessions/presentation/canini&lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;devoflow&quot;&gt;[6]A. R. Curtis, J. Mogul, J. Tourrilhes, P. Yalagandula, P. Sharma, and S. Banerjee, “DevoFlow: Scaling Flow Management for High-Performance Networks,” in &lt;i&gt;Proceedings of the ACM SIGCOMM 2011 Conference, SIGCOMM’11&lt;/i&gt;, 2011, vol. 41, pp. 254–265, doi: 10.1145/2018436.2018466. &lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;&lt;div style=&quot;word-wrap: break-word&quot;&gt;
&lt;span id=&quot;sdx&quot;&gt;[7]A. Gupta &lt;i&gt;et al.&lt;/i&gt;, “SDX: A Software Defined Internet Exchange,” in &lt;i&gt;Proceedings of the 2014 ACM Conference on SIGCOMM&lt;/i&gt;, New York, NY, USA, 2014, pp. 551–562, doi: 10.1145/2619239.2626300 [Online]. Available at: http://doi.acm.org/10.1145/2619239.2626300&lt;/span&gt;


&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;
</description>
        <pubDate>Fri, 05 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://carloalbertoscola.it//2019/network/sdn/software-defined-networking-introduction/</link>
        <guid isPermaLink="true">https://carloalbertoscola.it//2019/network/sdn/software-defined-networking-introduction/</guid>
        
        
        <category>network</category>
        
        <category>sdn</category>
        
      </item>
    
  </channel>
</rss>
